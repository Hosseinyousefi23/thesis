
\ูุตู{ูุนุฑู ฺูุฏ ุงูฺฏูุฑุชู ุฌุฏุฏ}
ุฏุฑ ูุตู ุฏูู ุฏุฏู ฺฉู ูุณุฆูู ุงุฏฺฏุฑ ุชููุชุ ุฏุฑ ุงุตู ฺฉ ูุณุฆูู ุจููู ุณุงุฒ ุงุณุช ฺฉู ูุฏู ุขู ุงูุชู ฺฉ ุฎุท\nf ูุด ุจููู (ุง ุฏุณุช\nf ฺฉู ุชูุฑุจ ุงุฒ ุขู) ุงุณุช ฺฉู ุฏุฑ ฺฉ ูุฑุขูุฏ ุชุตูู\nf ฺฏุฑ ูุงุฑฺฉูู ุชุนุฑู ู\nf ุดูุฏ. ููฺูู  ุจุง ูุนุงุฏูู ุจููู ู ุฑูุด\nf ูุง ุจุฑูุงููโุฑุฒ ูพูุง ุขุดูุง ุดุฏู. ุฏุฑ ุงู ูุตูุ ุฏู ุฑูฺฉุฑุฏ ุฌุฏุฏ ุจู ูุณุฆูู ุฎูุงูู ุฏุงุดุช ฺฉู ุงูฺฉุงู ุงุณุชูุงุฏู ุงุฒ ุฑูุด\nf ูุง ุจููู ุณุงุฒ ุดูุงุฎุชู ุดุฏู ูุงููุฏ 
\textit{\ููู{ุตุนูุฏ ฺฏุฑุงุฏุงู}}\LTRfootnote{Gradient Ascent}
ู
\textit{\ููู{ูุฒูู ฺฏุฑุงุฏุงู}}\LTRfootnote{Gradient Descent}
ุฑุง ุจุฑุง ุญู ูุณุฆูู ุงุฏฺฏุฑ ุชููุช ูุฑุงูู ู\nf ฺฉูุฏ. ุณูพุณ ุจุฑุฎ ุงุฒ ููู\nf ุชุฑู ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ุชููุช ุฌุฏุฏุ ูุงููุฏ
\lr{DQN}ุ
\lr{DDPG},
\lr{TRPO} ู 
\lr{Actor-Critic}
  ุฑุง ูุนุฑู ุฎูุงูู ฺฉุฑุฏ. 
\ูุณูุช{ุฏู ุฑูฺฉุฑุฏ ูุฎุชูู ุจู ูุณุฆูู}
 ุฏุฑ ูุตู ฺฏุฐุดุชู  ุฏุฏู ฺฉู ุจุง ุชุนุฑู ฺฉ ุชุฑุชุจ ุฌุฒุฆ ุฑู ุฎุท\nf ูุด\nf ูุง ููฺฉู ุจุฑุง ฺฉ
\lr{MDP}ุ
ู\nf ุชูุงู ุชุนุจุฑ ุจุฑุง ุฎุท\nf ูุด ุจููู ุงุฑุงุฆู ฺฉุฑุฏ. ุฏุฑ ุงู ูุตูุ ุชุนุฑู ุฏฺฏุฑ ุงุฒ ุฎุท ูุด ุจููู ุงุฑุงุฆู ุฎูุงูุฏ ุดุฏ.  ูุดุงู ุฏุงุฏู ฺฉู ู\nf ุชูุงู ุจุง ูุญุงุณุจู ุชุงุจุน ุงุฑุฒุด ฺฉ ุฎุท\nf ูุดุ ุขู ุฑุง ุจูุจูุฏ ุจุฎุดุฏ. ุงูฺฏูุฑุชู ุชฺฉุฑุงุฑ ุฎุท\nf ูุดุ ุจุง ุดุฑูุน ุงุฒ ฺฉ ุฎุท ูุด ุชุตุงุฏู ู ุจูุจูุฏ ุฏุงุฏู ุขู ุจู ุตูุฑุช ฺฏุงู\nf ุจู\nf ฺฏุงูุ ุจู ฺฉ ุฎุท\nf ูุด ุจููู ููฺฏุฑุง ู\nf ุดูุฏ.  ุจู ุทูุฑ ฺฉู ุจู ุฑูุด\nf ูุง ฺฉู ุจุง ุงุณุชูุงุฏู ุงุฒ ุจูุจูุฏ ฺฏุงู\nf ุจู\nf ฺฏุงู ุฎุท\nf ูุดุ ูุณุชููุง ุฎุท\nf ูุด ุจููู  ุฑุง ุชูุฑุจ ู\nf ุฒููุฏุ ุฑูุด\nf ูุง 
\textit{\ููู{ูุจุชู ุจุฑ ุฎุท\nf ูุด}}
\LTRfootnote{Policy Based}
ฺฏูุชู ู\nf ุดูุฏ. ุจูุงุจุฑุงู ุฑูุด ุชฺฉุฑุงุฑ ุฎุท\nf ูุดุ ฺฉู ุฏุฑ ูุตู ูุจู ูุนุฑู ุดุฏุ ฺฉ ุฑูุด ูุจุชู ุจุฑ ุฎุท\nf ูุด ุงุณุช.
 ููฺูู ุฏุฏู ฺฉู ููู ุฎุท\nf ูุด\nf ูุง ุจูููุ ุชุงุจุน ุงุฑุฒุด ูุดุชุฑฺฉ ุฏุงุฑูุฏ ฺฉู ุชุงุจุน ุงุฑุฒุด ุจููู ูุงูุฏู  ู\nf ุดูุฏ ู ุฏุฑ ูุนุงุฏูู\nf ุง ููุณูู ุจู ูุนุงุฏูู ุจููฺฏ ุจููู ุตุฏู ู\nf ฺฉูุฏ.
\ุดุฑูุน{ุชุนุฑู}[ุชุงุจุน ููุงุณ ุนููฺฉุฑุฏ] ูุฑุถ ฺฉูุฏ 
$\EuScript{M} = \seq{\EuScript{S},\EuScript{A},\EuScript{R},\EuScript{P}, \lambda}$ 
ฺฉ ูุฑุขูุฏ ุชุตูู\nf ฺฏุฑ ูุงุฑฺฉูู ู $\Pi$ ูุฌููุนู ุชูุงู ุฎุท\nf ูุด\nf ูุง ููฺฉู ุจุฑุง $\EuScript{M}$ ุจุงุดุฏ. ุชุงุจุน 
$J: \Pi \to \mathbb{R}$
ุจู ุดฺฉู ุฒุฑ ุชุนุฑู ู\nf ุดูุฏ
$$J(\pi) \triangleq \mathbb{E}_\pi(G_0)$$
\ูพุงุงู{ุชุนุฑู}
ููุธูุฑ ุงุฒ 
$G_0$ุ
ุนุงุฏ ุฏุฑ ุฒูุงู 
$t=0$
ุงุณุช. ุงุฒ ุชุนุฑู 
\ref{def:returninf}
ุฏุงุฑู
$$G_0 = \sum_{k=0}^{\infty} \gamma^{k} R_{k+1} = R_1 + \gamma R_2 + \gamma^2 R_3 + ...$$
ุจู ุชุงุจุน $J$ุ ุชุงุจุน ููุงุณ ุนููฺฉุฑุฏ ุฎุท\nf ูุด ฺฏูุชู ู\nf ุดูุฏ.
ุฎุท\nf ูุด ุจูููุ ุฎุท\nf ูุด\nf ุง ุงุณุช ฺฉู ููุงุณ ุนููฺฉุฑุฏ $J$ ุฑุง ุจุดูู ู\nf ฺฉูุฏ
$$arg \max_{\pi} J(\pi) = \Pi_*.$$
ุจุฑุฎ ุงุฒ ุงูฺฏูุฑุชู\nf ูุง ุงุฏฺฏุฑ ุชููุชุ ุฑูุด ุจุฑุง ูพุฏุงฺฉุฑุฏู ููุทู ุจุดูู ุชุงุจุน $J$ (ุง ุชูุฑุจ ุงุฒ ุขู) ุงุฑุงุฆู ู\nf ุฏููุฏ. ุฑูุด\nf ูุง ฺฉู ฺูู ุฑูฺฉุฑุฏ ุฏุงุฑูุฏุ ุฑูุด\nf ูุง 
\textit{\ููู{ูุจุชู ุจุฑ ุฎุท\nf ูุด}}\LTRfootnote{Policy Based}
 ูุงูุฏู ู\nf ุดููุฏ.
 
 ุฑูฺฉุฑุฏ ุฏฺฏุฑ ฺฉู ุจุฑุง ุญู ูุณุฆูู ุงุฏฺฏุฑ ุชููุช ูุฌูุฏ ุฏุงุฑุฏุ ูุญุงุณุจู ุชุงุจุน ุงุฑุฒุด ุญุงูุชุ ุง ุชุงุจุน ุงุฑุฒุด ุนูู ุจููู ุงุณุช. ููุธูุฑ ุงุฒ ุชุงุจุน ุงุฑุฒุด ุจูููุ ุชุงุจุน ุงุฑุฒุด ุงุณุช ฺฉู ุฏุฑ ูุนุงุฏูู ุจููฺฏ ุจููู 
 \ref{eq:bellman-opti}
 ุตุฏู ฺฉูุฏ. ุจุฑุฎ ุงุฒ ุฑูุด\nf ูุง ุงุฏฺฏุฑ ุชููุชุ ุฑูุด ุจุฑุง ูุญุงุณุจู ุชุงุจุน ุงุฑุฒุด ุจููู ุจุง ุงุณุชูุงุฏู ุงุฒ ูุนุงุฏูู ุจููฺฏ ุจููู ุงุฑุงุฆู ู\nf ุฏููุฏ. ุจู ุฑูุด\nf ูุง ฺฉู ฺูู ุฑูฺฉุฑุฏ ุฏุงุฑูุฏุ ุฑูุด\nf ูุง 
 \textit{
 	\ููู{ูุจุชู ุจุฑ ุงุฑุฒุด
 		}}\LTRfootnote{Value Based}
 ฺฏูุชู ู\nf ุดูุฏ.

\section{ุฑูุดโูุง ูุจุชู ุจุฑ ุฎุทโูุด}
ุฏุฑ ุงู ูุณูุช ุฑูุดโูุง ุฑุง ุฏุฑ ูุธุฑ ูโฺฏุฑู ฺฉู ุจุฑุง ุฏุณุชุงุจ ุจู ุฎุทโูุด ุจูููุ ุจู ุฌุง ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน ุงุฑุฒุดู ุนูู ุง ุงุฑุฒุดู ุญุงูุชุ ฺฉ ุฎุทโูุด ูพุงุฑุงูุชุฑโุดุฏู\LTRfootnote{Parameterized Policy} 
ุจุง ูพุงุฑุงูุชุฑูุง $\theta$ ุฑุง ูโุขููุฒุฏ.  ุงู ฺฉุงุฑ  ูุนูููุง ุชูุณุท ฺฉ ุดุจฺฉู ุนุตุจ ุจุง ูพุงุฑุงูุชุฑูุง 
$\theta \in \mathbb{R}^{d'}$
 ุจู ุนููุงู ุชูุฑุจ\nf ฺฏุฑ ุฎุท\nf ูุด 
$\pi$
ุดูุงุฎุชู ุดุฏู ู ุจุง ููุงุฏ $\pi_\theta$ ููุงุด ุฏุงุฏู ู\nf ุดูุฏ. ุงุญุชูุงู ุงูุชุฎุงุจ ุนูู $a$ ุฏุฑ ุญุงูุช $s$ ุชูุณุท ุฎุท\nf ูุด $\pi$ ุจุง ูพุงุฑุงูุชุฑูุง $\theta$ ุฑุง ุจู ุตูุฑุช
$\pi_\theta(a|s)$
ุง
$\pi(a|s;\theta)$
ููุงุด ุฎูุงูู ุฏุงุฏ.
ููฺฉู ุงุณุช ุจุฑุง ุงุฏฺฏุฑ ูพุงุฑุงูุชุฑูุง ุฎุทโูุด ุงุฒ ฺฉ ุชุงุจุน ุงุฑุฒุด ูุฒ ุงุณุชูุงุฏู ุดูุฏุ ุงูุง ุชุงุจุน ุงุฑุฒุด ุจุฑุง ุงูุชุฎุงุจ ุนูู ููุฑุฏ ูุงุฒ ูุณุช. 
%$\pi_\theta(a|s)$
ูพุงุฑุงูุชุฑูุง $\theta$ ุจุง ุงุณุชูุงุฏู ุงุฒ \ููู{ุตุนูุฏ ฺฏุฑุงุฏุงู}
\LTRfootnote{Gradian ascent}
ุฑู ููุงุณ ุนููฺฉุฑุฏ\LTRfootnote{Performance Measure} 
$J(\pi_\theta)$
(ุง ุจู ุงุฎุชุตุงุฑ $J(\theta)$)
ุจู ุทูุฑ ูุณุชูู ู ุง ุจุง ุจุดููโุณุงุฒ ุชุฎููโูุง ูุญู ุงุฒ  $J(\theta)$ ุจู\nf ุฑูุฒุฑุณุงู ูโุดููุฏ.
ุงู ุฑูุด\nf ูุง ุชูุฑุจุง ููุดู ุจู ุตูุฑุช ุจุฑ-ุฎุท\nf ูุด  ุนูู ูโฺฉููุฏ. 
 ูุฏู ุงู ุฑูุดโูุง ุจุดูู ฺฉุฑุฏู ููุงุณ ุนููฺฉุฑุฏ ุงุณุช. 
 
 
 \subsection{ุฑูุด ฺฏุฑุงุฏุงู ุฎุท\nf ูุด}
ุฑูุด ฺฏุฑุงุฏุงู ุฎุท\nf ูุดุ ุณุงุฏู\nf ุชุฑู ู ูพุงู\nf ุง\nf ุชุฑู ุฑูุดุ ุฏุฑ ูุงู ุฑูุด\nf ูุง ูุจุชู ุจุฑ ุฎุท\nf ูุด ุงุณุช. ุฏุฑ ุงู ุฑูุดุ ุฏูุจุงูู\nf 
ุง ุงุฒ ูพุงุฑุงูุชุฑูุง ุฎุท\nf ูุดุ 
$\theta_0, \theta_1, \theta_2, ...$
ุชููุฏ ู\nf ุดูุฏ ฺฉู $\theta_0$ ุจู ุตูุฑุช ุชุตุงุฏู ููุฏุงุฑุฏู ู\nf ุดูุฏ ู ุงุฒ ุฌููู 
$\theta_1$
ุจู ุจุนุฏุ ูุฑ ุฌูููุ ุงุฒ ุฑู ุฌููู ูุจู ุชูุณุท ูุงููู ุจู\nf ุฑูุฒุฑุณุงู ุฒุฑ ุจู\nf ุฏุณุช ู\nf ุขุฏ
\begin{align}
\theta_{t+1} \doteq \theta_t + \alpha \widehat{\nabla J(\theta_t)}.
\label{eq:updatepg}
\end{align}
ฺฉู 
$\widehat{\nabla J(\theta_t)}$
ุชุฎูู ูุงุงุฑุจ ุงุฒ ฺฏุฑุงุฏุงู  $J$ ูุณุจุช ุจู 
$\theta_t$
 ู\nf ุจุงุดุฏ ฺฉู ุงุฒ ููููู ุชุฌุฑุจู ุดุฏู ุจู\nf ุฏุณุช ู\nf ุขุฏ ู $\alpha$ ฺฉ ุนุฏุฏ ุญูู ูุซุจุช ุงุณุช ฺฉู 
 \textit{ุถุฑุจ ุงุฏฺฏุฑ}\LTRfootnote{Learning Coefficient}
 ูุงูุฏู ู\nf ุดูุฏ. ู\nf ุชูุงู ูุดุงู ุฏุงุฏ ฺฉู ุฏูุจุงูู ุฎุท\nf ูุด\nf ูุง
 $\pi_{\theta_0}, \pi_{\theta_1}, \pi_{\theta_2}, ...$
 ุจู ฺฉ ุฎุท ูุด ุจููู $\pi_*$ ููฺฏุฑุง ู\nf ุดูุฏ. ุณุฑุนุช ุงู ููฺฏุฑุงุ ุจู ูุงุฑุงูุณ ุชุฎููฺฏุฑ ฺฏุฑุงุฏุงู ูุงุจุณุชู ุงุณุชุ ูุฑ ฺู ูุงุฑุงูุณ ุจุฒุฑฺฏุชุฑ ุจุงุดุฏุ ููฺฏุฑุง ุฏุฑุชุฑ ุงุชูุงู ู\nf ุงูุชุฏ. ุจู ุฑูุดโูุง ฺฉู ฺูู ุงูฺฏู ุฑุง ุจุฑุง ูุญุงุณุจู ุฎุทโูุด ุจููู ุฏูุจุงู ูโฺฉููุฏุ ุฑูุดโูุง \textit{ฺฏุฑุงุฏุงู ุฎุทโูุด }\LTRfootnote{Policy Gradient} ฺฏูุชู ู\nf ุดูุฏ. 

\ุดุฑูุน{ูุถู}[ฺฏุฑุงุฏุงู ุฎุทโูุด] ุงู ูุถู ุจุงู ู\nf ฺฉูุฏ ฺฉู
\begin{align}
	\nabla J(\theta) \propto \mathbb{E}_\pi \left[ G_t \frac{\nabla_\theta \pi (A_t|S_t; \theta)}{\pi(A_t|S_t); \theta} \right]
	\label{eq:pg}
\end{align}
%\sum_{s} \mu(s) \sum_{a} q_\pi(s,a) \nabla_\theta \pi_\theta(a|s)
%ฺฉู $\mu$ ฺฉ ุชูุฒุน ุงุญุชูุงู ุฑู 
%$\EuScript{S}$
% ุงุณุช ฺฉู ูุชูุงุณุจ ุจุง ุชุนุฏุงุฏ ุฏูุนุงุช ุงุณุช ฺฉู ุญุงูุช $s$ ุจุง ุฏูุจุงู ฺฉุฑุฏู ุฎุทโูุด 
%$\pi_\theta$
%ุชฺฉุฑุงุฑ ูโุดูุฏ.
\ุจุฑฺุณุจ{th:pg}
\ูพุงุงู{ูุถู}
\ุดุฑูุน{ุงุซุจุงุช}
ุฑุฌูุน ุดูุฏ ุจู 
\cite{suttonbook}
\ูพุงุงู{ุงุซุจุงุช}

\subsection{ุงูฺฏูุฑุชู REINFORCE}

ฺฉ ููููู ุงุฒ ุฑูุดโูุง ุจูููโุณุงุฒ ุฎุทโูุดุ ุฎุงููุงุฏู
\lr{REINFORCE}
ุงุฒ ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ุชููุช ุงุณุช
\cite{williams1992simple}.
ุงูฺฏูุฑุชู ุงุณุชุงูุฏุงุฑุฏ \lr{REINFORCE} ูพุงุฑุงูุชุฑูุง $\theta$ ุฑุง ุฏุฑ ุฌูุช 
$G_t \nabla_\theta  log  \pi (a_t|s_t;\theta)$ ุจูโุฑูุฒุฑุณุงู ูโฺฉูุฏ ฺฉู ฺฉ ุชุฎูู ูุงุงุฑุจ ุงุฒ
$\nabla_\theta J(\theta)$
ุงุณุช.
%ูโุชูุงู ูุดุงู ุฏุงุฏ 
%$$\nabla J(\pi_\theta) = \mathbb{E}_\pi \left[ R_t \frac{\nabla_\theta \pi_\theta (a|S_t)}{\pi_\theta (a|S_t)} \right]$$
ุจุง ุชูุฌู ุจู ูุถู 
\ref{th:pg}
ุฏุฑ ฺฏุงู $t$ุ
$\left[ G_t \frac{\nabla_\theta \pi_\theta (a|S_t)}{\pi_\theta (a|S_t)} \right]$
ฺฉ ุชุฎููโฺฏุฑ ูุงุงุฑุจ ุงุฒ $\nabla J(\pi_\theta)$ ุฎูุงูุฏ ุจูุฏ \cite{suttonbook}. ูพุณ ูโุชูุงู ุฏุฑ ูุฑ ฺฏุงูุ ูพุงุฑุงูุชุฑูุง ุฎุท\nf ูุด
 ุฑุง ุจู ุดฺฉู ุฒุฑ ุจูโุฑูุฒุฑุณุงู ฺฉุฑุฏ
$$\theta_{t+1} \doteq \theta_t + \alpha G_t \frac{\nabla_\theta \pi_\theta (a|S_t)}{\pi_\theta (a|S_t)} = \theta_t + \alpha G_t \nabla_\theta log \pi_\theta (a|S_t)$$

\ุดุฑูุน{ุงูฺฏูุฑุชู}{ุงูฺฏูุฑุชู ุฏูุฑู\nf ุง 
\lr{REINFORCE} }
\ูุฑูุฏ{ฺฉ ุชุงุจุน ูพุงุฑุงูุชุฑ ูุดุชู ูพุฐุฑ ุงุฒ ุฎุทโูุด 
	$\pi(a|s;\theta)$}

\ุฏุณุชูุฑ{ูพุงุฑุงูุชุฑูุง ุฎุทโูุด 
	$\theta \in \mathbb{R}^{d'}$
	ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู
}
\ุจูโุงุฒุง{ุชฺฉุฑุงุฑ ฺฉู}
%\ุงฺฏุฑ{$|E| > 0$}
%	\ุฏุณุชูุฑ{ฺฉ ฺฉุงุฑ ุงูุฌุงู ุจุฏู}
%\ูพุงุงูโุงฺฏุฑ
\ุฏุณุชูุฑ{ฺฉ ุฏูุฑู 
	$S_0,A_0,R_1,..., S_{T-1}, A_{T-1}, R_T$
	 ุฑุง ุจุง ุฏูุจุงู ฺฉุฑุฏู ุฎุท\nf ูุด $\pi_\theta$ ุจุณุงุฒ}

\ุจูโุงุฒุง{ุจุฑุง ูุฑ ฺฏุงู
$t=0,...,T-1$}
\ุฏุณุชูุฑ{
$G_t$
$\longrightarrow$
	 ุนุงุฏ ฺฏุงู $t$ ุงู
	 


}
\ุฏุณุชูุฑ{
$\theta + \alpha \gamma^t G_t \nabla_\theta ln \pi (A_t|S_t;\theta) \longrightarrow \theta$
}
\ูพุงุงูโุจูโุงุฒุง
\ูพุงุงู{ุงูฺฏูุฑุชู}
%ฺูุฏ ููููู ุงุฒ ุฑูุดโูุง ุจูููโุณุงุฒ ุฎุทโูุด ุจู ุดุฑุญ ุฒุฑ ุงุณุช. \\
%ุฑูุดโูุง ุจุงุฒฺฏุฑ ููุชูุฏ
%\LTRfootnote{Actor-Critic}
%ฺฉู ุงูฺฏูุฑุชู 
%ฺฏุฑุงุฏุงู ุงูุฒุงุด
%ุฑุง ูุณุชููุง ุจุฑุง ุจุดูู ุณุงุฒ 
%$J(\pi\theta)$
%ุจู ฺฉุงุฑ ูโุจุฑูุฏ.
%ุฑูุด  
%\lr{Proximal Policy Optimization}
%ฺฉู!!!!!!!!!!!

\subsubsection{ุฑูุดโูุง ุจุงุฒฺฏุฑ-ููุชูุฏ}
ุฏุฑ ุจุฎุด ูุจูุ ุจุง ุฑูุด ฺฏุฑุงุฏุงู ุฎุท\nf ูุด ู ฺฉ ุฑูุด ุนูู ุขู ุนู ุงูฺฏูุฑุชู
\lr{REINFORCE}
ุขุดูุง ุดุฏู. ุฏุณุชูโุง ุงุฒ ุฑูุดโูุง ฺฏุฑุงุฏุงู ุฎุทโูุด ูุฌูุฏ ุฏุงุฑูุฏ ฺฉู ุนูุงูู ุจุฑ ุจูุจูุฏ ฺฏุงู ุจู ฺฏุงู ุฎุท \nf ูุดุ ุชุฎูู ุงุฒ ุชุงุจุน ุงุฑุฒุด  ุญุงูุช ูุฑุจูุท ุจู ุขู ุฎุท\nf ูุด ุฑุง ูุฒ ูุญุงุณุจู ฺฉููุฏ. ุจู ฺูู ุฑูุดโูุงุ \textit{\ููู{ุจุงุฒฺฏุฑ-ููุชูุฏ}} 
\LTRfootnote{Actor-Critic}
ฺฏูุชู ูโุดูุฏ ฺฉู \textit{\ููู{ุจุงุฒฺฏุฑ}} 
\LTRfootnote{Actor}
ุงุดุงุฑู ุจู ุฎุทโูุด ุขููุฎุชู ุดุฏู ู \textit{\ููู{ููุชูุฏ}} 
\LTRfootnote{Critic}  
ุงุดุงุฑู ุจู ุชุงุจุน ุงุฑุฒุด ุขููุฎุชู ุดุฏู (ูุนูููุง ฺฉ ุชุงุจุน ุงุฑุฒุดู ุญุงูุช) ุฏุงุฑุฏ.

ุจุง ฺฉู ฺฉุฑุฏู ฺฉ ุชุงุจุน ุฏูุฎูุงู ุฑู ุญุงูุชโูุงุ 
$b_t(s)$
ุงุฒ 
$G_t$
ุฏุฑ ุทุฑู ุฑุงุณุช ุฑุงุจุทู 
\ref{eq:pg}ุ
ู\nf ุชูุงู ุจู ุชุนูู ุงุฒ ูุถู 
\ref{[th:pg]}
ุฏุณุช ุงูุช
\begin{align}
	\nabla J(\theta) \propto \mathbb{E}_\pi \left[ (G_t-b(s)) \frac{\nabla_\theta \pi (A_t|S_t; \theta)}{\pi(A_t|S_t); theta} \right]
	\label{eq:pgbase}
\end{align}
ุจุฑุง ุงุซุจุงุช ุฏุฑุณุช ุฑุงุจุทู
\ref{eq:pgbase}
ฺฉุงูุณุช ูุดุงู ุฏูู
$\mathbb{E}_\pi \left[b(s)\right] \frac{\nabla_\theta \pi (A_t|S_t; \theta)}{\pi(A_t|S_t); theta} = 0$
ูุงุฑุงูุณ ุงู ุชุฎูู ุฑุง ฺฉุงูุด ุฏุงุฏ ุจูโุทูุฑโฺฉู ูุงุงุฑุจ ุจุงู ุจูุงูุฏ. ุจู ฺูู ุชุงุจุน \ููู{ูพุงู} ฺฏูุชู ูโุดูุฏ. 
ุฏุฑ ูุชุฌู ฺฏุฑุงุฏุงู ุจู ุดฺฉู
$\nabla_\theta \ log \ \pi(a_t|s_t;\theta) (R_t - b_t(s_t))$
ุฎูุงูุฏ ุจูุฏ. ูุนูููุง ุงุฒ ุชุฎูู ุขููุฎุชูโุดุฏู ุงุฒ ุชุงุจุน ุงุฑุฒุด ุจู ุนููุงู ูพุงู ุงุณุชูุงุฏู ูโุดูุฏุ
$b_t(s_t) \approx v_\pi (s_t)$ุ
ฺฉู ููุฌุฑ ุจู ุชุฎูู ุจุง ูุงุฑุงูุณ ุจุณุงุฑ ฺฉูฺฺฉโุชุฑ ุงุฒ ฺฏุฑุงุฏุงู ุฎุทโูุด ูโโุดูุฏุ ุฏุฑ ุญุงูโฺฉู ุชุฎูู ูุงุงุฑุจ ุจุงู ูโูุงูุฏ ู ุฏุฑูุชุฌู ุนููุงุช ุงุฏฺฏุฑ ุจุง ุณุฑุนุช ุจุดุชุฑ ุงูุฌุงู ูโุดูุฏ.
ุงู ุฑูุด ูโุชูุงูุฏ ุจู ุดฺฉู ูุนูุงุฑ \ููู{ุจุงุฒฺฏุฑ-ููุชูุฏ}  ุชุนุจุฑ ุดูุฏ ฺฉู ุฎุทโูุด $\pi$ \ููู{ุจุงุฒฺฏุฑ} ู ูพุงู $b_t$ \ููู{ููุชูุฏ} ุงุณุช. ุงฺฏุฑ ุงุฒ ุชุฎูู ฺฉ ุชุงุจุน ุงุฑุฒุดู ุญุงูุช ุจู ุนููุงู ูพุงู ุงุณุชูุงุฏู ฺฉูู 
$b_t(s) = v_{\pi_{\theta_t}}(s)$ ุนุจุงุฑุช $R_t - b_t(s)$ ูโุชูุงูุฏ ุจู ุดฺฉู ุชุฎูู ุงุฒ \ููู{ูุฒุช} \LTRfootnote{Advantage} ุนูู $a_t$ ุฏุฑ ุญุงูุช $s_t$ ุง 
$A(a_t,s_t)=Q(a_t,s_t)-v(s_t)$ ุชุนุจุฑ ุดูุฏ. ฺุฑุงฺฉู $R_t$ ุชุฎูู ุงุฒ  $Q_\pi (a_t, s_t)$ ู $b_t$ ุชุฎูู ุงุฒ  $v_\pi (s_t)$ ุงุณุช. ุฏุฑ ุงู ุตูุฑุช ุจู ุงู ุฑูุด 
\lr{Advantage Actor-Critic}
ุง A2C ฺฏูุชู ูโุดูุฏ.
\ุดุฑูุน{ุงูฺฏูุฑุชู}{ุงูฺฏูุฑุชู $Advantage Actor-Critic$ }
\ูุฑูุฏ{ฺฉ ูพุงุฑุงูุชุฑโุดุฏู ูุดุชู ูพุฐุฑ ุงุฒ ุฎุทโูุด 
	$\pi_\theta(a|s)$}
\ูุฑูุฏ{ฺฉ ูพุงุฑุงูุชุฑโุดุฏู ูุดุชูโูพุฐุฑ ุงุฒ ุชุงุจุน ุงุฑุฒุดู ุญุงูุช 
	$v_\omega(s)$}
\ุฏุณุชูุฑ{ูพุงุฑุงูุชุฑูุง ุฎุทโูุด 
	$\theta \in \mathbb{R}^{d'}$
	ู ุชุงุจุน ุงุฑุฒุดู ุญุงูุช
	$\omega \in \mathbb{R}^d$
	ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู
}
\ุจูโุงุฒุง{ุชฺฉุฑุงุฑ ฺฉู}
%\ุงฺฏุฑ{$|E| > 0$}
%	\ุฏุณุชูุฑ{ฺฉ ฺฉุงุฑ ุงูุฌุงู ุจุฏู}
%\ูพุงุงูโุงฺฏุฑ
\ุฏุณุชูุฑ{ุญุงูุช ุงููู $S$ ุฑุง ุจุณุงุฒ}
\ุฏุณุชูุฑ{$1 \longrightarrow I$}
\ุชุงููุช{$S$ ุญุงูุช ููุง ูุณุช}
\ุฏุณุชูุฑ{
	$A \sim \pi_\theta(.|S)$
}
\ุฏุณุชูุฑ{ุนูู $A$ ุฑุง ุงูุฌุงู ุจุฏู ู ุญุงูุช $S'$ ู ูพุงุฏุงุด $R$ ุฑุง ูุดุงูุฏู ฺฉู}

\ุฏุณุชูุฑ{
	$ \longrightarrow \delta$
	$R + \gamma v_\omega(S') - v_\omega(S)$
}
\ุฏุณุชูุฑ{
	$ \longrightarrow \omega$
	$\omega + \alpha^\omega I \delta \nabla_\omega v_\omega(S)$
}
\ุฏุณุชูุฑ{
	$ \longrightarrow \theta$
	$\theta +  \alpha^\theta   I  \delta \nabla_\theta \ ln \ \pi_\theta(A| S)$
}

\ุฏุณุชูุฑ{
	$\gamma I \longrightarrow I$
}

\ุฏุณุชูุฑ{
	$S' \longrightarrow S$
}
\ูพุงุงูโุชุงููุช
\ูพุงุงูโุจูโุงุฒุง
%\caption{ ุจุฑฺฏุฑูุชู ุดุฏู ุงุฒ !!!!!!!!!!!!}
\ูพุงุงู{ุงูฺฏูุฑุชู}
\subsubsection{ุฑูุด TRPO}
%\ูุณูุช{ุฑูุด TRPO}
\ุดุฑูุน{ุชุนุฑู}
ุงฺฏุฑ
$\rho_\pi : S \longrightarrow \mathbb{R}$
ุชุงุจุน ูุฑฺฉุงูุณ ุชุฎููโุฏุงุฑ ุฏุฏู ุดุฏู ุญุงูุชโูุง ุจุงุดุฏ. ุนู $$\rho_\pi(s) = P(S_0=s) + \gamma P(S_1=s) + \gamma^2 P(S_2=s) + ...$$ \\ฺฉู ุฏูุจุงูู $S_0, S_1, S_2$ ุฎุทโูุด $\pi$ ุฑุง ุฏูุจุงู ูโฺฉูุฏ.
\ูพุงุงู{ุชุนุฑู}
ุงฺฏุฑ $\pi$ ู $\pi'$ ุฏู ุฎุทโูุด ุจุงุดูุฏ ู  $J(\pi) = \mathbb{E}_\pi[R_0]$  ูโุชูุงู ูุดุงู ุฏุงุฏ 
$$J(\pi')= J(\pi) + \sum_{s} \rho_{\pi'}(s) \sum_{a} \pi'(a|s) A_\pi(s,a)$$ ฺฉู  $A_\pi(s,a) = Q_\pi (s,a) - V_\pi(s)$ ุชุงุจุน ูุฒุช ุนูู $a$ ุฏุฑ ุญุงูุช $s$ ุจุงุดุฏ.
ูุงุจุณุชฺฏ ูพฺุฏู  $\rho_\pi'(s)$ ุฏุฑ ุทุฑู ุฑุงุณุช ุชุณุงู ุจู $\pi'$ ุจูููโุณุงุฒ ูุณุชูู ุฑุง ูุดฺฉู ูโฺฉูุฏ.
ุจุฑุง ุญู ุงู ูุดฺฉู ุดูููู ู ููฺฉุงุฑุงูุด 
ููุงุณ ุนููฺฉุฑุฏ ุฏฺฏุฑุ $L_\pi(\pi')$ุ ุฑุง ูุนุฑู ูโฺฉูุฏ ู ูุดุงู ูโุฏูุฏ ฺฉู ุงฺฏุฑ $\pi$ ู $\pi'$ ุจู ุงูุฏุงุฒู ฺฉุงู ุจู ฺฉุฏฺฏุฑ ูุฒุฏฺฉ ุจุงุดูุฏุ ุงูุฒุงุด  $L_\pi(\pi')$  ูููุงุฑู ุจุง ุงูุฒุงุด $J$ ููุฑุงู ุฎูุงูุฏโุจูุฏ \cite{schulman2015trust}.
\begin{align}
	L_\pi(\pi')= J(\pi) + \sum_{s} \rho_{\pi}(s) \sum_{a} \pi'(a|s) A_\pi(s,a)
	\label{l_pi}
\end{align}
ุฏุฑ ุนุจุงุฑุช 
\ref{l_pi}
$L_\pi$ ุงุฒ ุชุงุจุน ูุฑฺฉุงูุณ $\rho_\pi$ ุจู ุฌุง $
\rho_{\pi'}$
ุงุณุชูุงุฏู ูโฺฉูุฏ.

\ุดุฑูุน{ูุถู}
ูุฑุถ ฺฉูุฏ 
$\alpha = D_{TV}^max(\pi_{old}, \pi_{new})$
ุจุงุดุฏ ฺฉู 
$$D_{TV}^max (\pi, \pi') = \max_{s} D_{TV}(\pi(.|s) || \pi'(.|s)$$
ู 
$D_{TV}(p || q)$
ุฏูุฑฺุงูุณ 
\lr{total variation}
ุจู ุฏู ุจุฑุฏุงุฑ $p$ ู $q$ ุจุงุดุฏ
$$D_{TV}(p || q) = \dfrac{1}{2} \sum_{i} |p_i - q_i|$$ ุฏุฑ ุงู ุตูุฑุช
$$J(\pi_{new}) \ge L_{\pi_{old}}(\pi_{new}) - \dfrac{4 \epsilon \gamma}{(1- \gamma)^2}$$ ฺฉู $\epsilon = \max_{s,a} |A_\pi(s,a)|$.
\label{q:ghas}
\ูพุงุงู{ูุถู}
ุจุง ุชูุฌู ุจู ูุถู \ref{q:ghas} ู ูุงูุนุงุฏูู $D_{TV}(p || q)^2 \le D_{KL}(p || q)$  ฺฉู  $D_{KL} (p || q)$ ุจุฑุงุจุฑ ุจุง ุฏูุฑฺุงูุณ KL ุฏู ุจุฑุฏุงุฑ $p$ ู $q$ ุงุณุช\cite{schulman2015trust}. ูโุชูุงู  ูุชุฌู ฺฏุฑูุช
\begin{align*}
	J(\pi') \ge L_{\pi}(\pi') - C \ D_{KL}^max(\pi, \pi')
\end{align*}
ฺฉู
\begin{align}
	C = \dfrac{4 \epsilon \gamma}{(1-\gamma)^2}
	\label{eq:cc}
\end{align}
ุฑุงุจุทู \ref{eq:cc} ูุดุงู ูโุฏูุฏ ฺฉู ูโุชูุงู ฺฉ ุฏูุจุงูู ุตุนูุฏ ุงุฒ ุฎุทโูุดโูุง ุฏุงุดุช ุจูโุทูุฑโฺฉู
$$J(\pi_0) \le J(\pi_1) \le J(\pi_2) \le ... $$
ฺุฑุง ฺฉู ูุฑุถ ฺฉูุฏ
$M_i(\pi) = L_{\pi_i}(\pi) - C \ D_{KL}^max(\pi_i, \pi)$
ุฏุฑ ุงู ุตูุฑุช $$J(\pi_{i+1}) \ge M_i(\pi{i+1}) $$ 
$$J(\pi_i) = M_i(\pi_i)$$
ุจูุงุจุฑุงู
$$J(\pi_{i+1}) - J(\pi_i) \ge M_i(\pi_{i+1}) - M_i(\pi_i)$$
ูโุชูุงู ูุชุฌู ฺฏุฑูุช ุจุง ุจุดูู ฺฉุฑุฏู $M_i$ ุฏุฑ ูุฑ ฺฏุงู ูโุชูุงู ุงุทููุงู ุญุงุตู ฺฉุฑุฏ ฺฉู ููุงุณ ุนููฺฉุฑุฏ ูุงูุน $J$ ุบุฑูุฒูู ุฎูุงูุฏ ุจูุฏ.
\ุดุฑูุน{ุงูฺฏูุฑุชู}{ุงูฺฏูุฑุชู $Policy Iteration$ ุจุง ููุงุณ ุนููฺฉุฑุฏ $L_\pi$}

\ุฏุณุชูุฑ{ุฎุทโูุด $\pi_0$
	ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู
}
\ุจูโุงุฒุง{ุจุฑุง 
	$i=0,1,...$
	ุชฺฉุฑุงุฑ ฺฉู}
%\ุงฺฏุฑ{$|E| > 0$}
%	\ุฏุณุชูุฑ{ฺฉ ฺฉุงุฑ ุงูุฌุงู ุจุฏู}
%\ูพุงุงูโุงฺฏุฑ
\ุฏุณุชูุฑ{ููู ูุฒุชโูุง 
	$A_{\pi_i}(s,a)$
	ุฑุง ูุญุงุณุจู ฺฉู
}
\ุฏุณุชูุฑ{
	$arg \max_{\pi} [L_{\pi_i}(\pi) - C \ D_{KL}^max(\pi_i, \pi)] \longrightarrow \pi_{i+1} = $
	ฺฉู 
	$$C = (4 \epsilon \gamma) / (1-\gamma)^2$$ ู  $$L_{\pi_i}(\pi) = J(\pi_i) + \sum_{s} \rho_{\pi_i}(s) \sum_{a} \pi(a|s) A_{\pi_i} (s,a)$$
}
\ูพุงุงูโุจูโุงุฒุง
\ูพุงุงู{ุงูฺฏูุฑุชู}
ุงฺฏุฑ $\hat{A}_t$ ุชุฎูู ูุฒุช 
$A_{\pi_t}(S_t, A_t)$
ุจุงุดุฏ ฺฉู ุฏุฑ ฺฏุงู $t$ ูุญุงุณุจู ูโุดูุฏุ ูโุชูุงู ูุดุงู ุฏุงุฏ ฺฉู ุฏุฑ ุฑูุด
\lr{TRPO}
ููุงุณ ุนููฺฉุฑุฏ $L_\pi$ ุฏุฑ ูุฑ ฺฏุงู ุจู ุดฺฉูุ
$$\mathbb{E}_t\left[\dfrac{\pi_{\theta_{new}}(A_t| S_t)}{\pi_{\theta_{old}}(A_t|S_t)} \hat{A}_t \right]$$ุฎูุงูุฏ ุจูุฏ.
\subsubsection{ุฑูุด PPO}
%\ูุณูุช{ุฑูุด PPO}
ุฏุฑ ุฑูุด \lr{TRPO} ุฏุฏู ฺฉู ุจุดููโุณุงุฒ ููุงุณ ุนูฺฉูุฑุฏ $L_\pi$ ุณุงุฏูโุชุฑ ุงุฒ ููุงุณ ุนููฺฉุฑุฏ $J$ ุงุณุช ูู ุฏุฑ ุนูุถ ุงูฺฏูุฑุชู ุตุนูุฏ ฺฏุฑุงุฏุงู ุชููุง ูุฌุงุฒ ุจู ุงุนูุงู ุชุบุฑุงุช ฺฉูฺฺฉ ุฏุฑ ุฎุทโูุด ุงุณุช. ฺฉ ุฑุงู ุฏฺฏุฑ ุจุฑุง ฺฉูุชุฑู ุชุบุฑุงุช ุฎุทโูุด ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน CLIP ุงุณุช. ุฏุฑ ุฑูุด
\lr{TRPO}
ุฏุฏู ฺฉู ุชุงุจุน ููุงุณ ุนููฺฉุฑุฏุ ุฏุฑ ฺฏุงู $t$ ุจู ุดฺฉู ุฒุฑ ุงุณุชุ
$$L_{\pi_{old}}(\pi_{new}) = \mathbb{E_t}\left[\dfrac{\pi_{\theta_{new}}(A_t| S_t)}{\pi_{\theta_{old}}(A_t|S_t)} A_{\pi}(S_t, A_t)\right]$$
ูุฑุถ ฺฉูุฏ 
$r_t(\theta_{new})$
ูุณุจุช ุงุญุชูุงูุงุช 
$r_t(\theta_{new}) = \dfrac{\pi_{\theta_{new}}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}$ ุจุงุดุฏ. ุจูุงุจุฑุงู
$$L_{\pi_{old}}(\pi_{new}) = \mathbb{E}_t\left[\dfrac{\pi_{\theta_{new}}(A_t| S_t)}{\pi_{\theta_{old}}(A_t|S_t)} A_{\pi}(S_t, A_t)\right] = \mathbb{E}_t\left[r_t(\theta_{new}) A_{\pi_{old}}(S_t,A_t)\right].$$ ููุงุณ ุนููฺฉุฑุฏ  $L^{CLIP}(\theta)$ ุฑุง ุจู ุดฺฉู ุฒุฑ ุชุนุฑู ูโฺฉูู
$$L^{CLIP}(\theta) = \mathbb{E}_t\left[min(r_t(\theta) \hat{A}_t, clip(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right]$$
ฺฉู $\epsilon$ ฺฉ ุงุจุฑูพุงุฑุงูุชุฑ \LTRfootnote{Hyperparameter} ูุซูุง 
$\epsilon=0.2$
ุงุณุช. ุงููู ุนุจุงุฑุช ุฏุงุฎู min ููุงู ููุงุณ ุนููฺฉุฑุฏ ุฑูุด \lr{TRPO} ุงุณุช. ุฏุฑ ุนุจุงุฑุช ุฏูู ููุงุฏุฑ ุจุฒุฑฺฏุชุฑ ุงุฒ $1+\epsilon$ ุง ฺฉูฺฺฉุชุฑ ุงุฒ 
$1-\epsilon$
ุฏุฑ $r_t(\theta)$ ุจู ุชุฑุชุจ ุจู $1+\epsilon$ ู $1-\epsilon$ ุชุบุฑ ูพุฏุง ฺฉุฑุฏูโุงูุฏ ุชุง ุชุบุฑุงุช ุจุฒุฑฺฏ ุฎุทโูุด ุฑุง ฺฉูุชุฑู ฺฉููุฏ. ููุงุชุง ุนุจุงุฑุช ฺฉูฺฺฉุชุฑ ุงุฒ ูุงู ุงู ุฏู ุงูุชุฎุงุจ ุฎูุงูุฏ ุดุฏ. ุจูุงุจุฑุงู ุงฺฏุฑ ููุงุณ ุนููฺฉุฑุฏ clip ูุดุฏู (ุนุจุงุฑุช ุงูู) ฺฉูฺฺฉุชุฑ ุง ูุณุงู ุจุง ุญุงูุช clip ุดุฏู (ุนุจุงุฑุช ุฏูู) ุจุงุดุฏุ $L^{CLIP}$ ุฏููุง ููุงู ููุงุณ ุนููฺฉุฑุฏ $L_\pi$ ุฎูุงูุฏ ุจูุฏ. ุฏุฑ ุบุฑ ุงู ุตูุฑุช ููุงุณ ุนููฺฉุฑุฏ clip ุดุฏู ุงูุชุฎุงุจ ูโุดูุฏ ุชุง ุงุฒ ุชุบุฑุงุช ุจุฒุฑฺฏ ุฎุทโูุด ุฌููฺฏุฑ ุดูุฏ.

\section{ุฑูุดโูุง ูุจุชู ุจุฑ ุงุฑุฒุด}
%\ูุณูุช{ุฑูุดโูุง ูุจุชู ุจุฑ ุงุฑุฒุด}


ุฏุฑ ุฑูุดโูุง ุงุฏฺฏุฑู ุชููุช ุจุฏูู ูุฏู ูุจุชู ุจุฑ ุงุฑุฒุด
ุชุงุจุน ุงุฑุฒุด ุนูู ุจุง ุงุณุชูุงุฏู ุงุฒ  ฺฉ ุชุฎููโฺฏุฑ ุชุงุจุน
\LTRfootnote{Function approximator}
 ุ ูุงููุฏ ุดุจฺฉู ุนุตุจ ุ ูุดุงู ุฏุงุฏู ูโุดูุฏ. ูุฑุถ ฺฉูุฏ
$Q(s,a;\theta)$
ฺฉ ุชุงุจุน ุงุฑุฒุด ุนูู ุชูุฑุจ ุจุง ูพุงุฑุงูุชุฑ  
$\theta$ 
ุจุงุดุฏ.
ุงูฺฏูุฑุชูโูุง ูุฎุชูู ุจุฑุง ุจูโุฑูุฒุฑุณุงู $\theta$ ูุฌูุฏ ุฏุงุฑุฏ.
ุงูฺฏูุฑุชู $ Q-learning$ ฺฉ ุงุฒ ูููููโูุง ฺูู ุงูฺฏูุฑุชูโุงุณุช
ฺฉู ูุฏู ุขู ุชูุฑุจ ูุณุชูู ุชุงุจุน ุงุฑุฒุดู ุนูู ุจููู 
$Q^*(s,a) \approx Q(s,a: \theta)$
 ุงุณุช. ุฏุฑ $ Q-learning$ ฺฉ ูุฑุญููโุงุ ูพุงุฑุงูุชุฑูุง $\theta$ ุงุฒ ุชุงุจุน ุงุฑุฒุดู ุนูู ุจุง ุจู ุญุฏุงูู ุฑุณุงูุฏู ุชุงุจุน ูุฒูู ุจู ุดฺฉู ูุฑุญูู ุจู ูุฑุญูู ุขููุฎุชู ูโุดููุฏุ ุจู ุดฺฉู ฺฉู ุชุงุจุน ูุฒูู $i$ุงู ุจู ุดฺฉู 
$$L_i(\theta_i) = \mathbb{E} {\left( r+\gamma \max_{a'} Q(s',a'; \theta_{i-1})- Q(s,a:\theta_i) \right)}^2$$
 ุชุนุฑู ูโุดูุฏ ฺฉู 
 $s'$
 ุญุงูุช ุงุณุช ฺฉู ุจุนุฏ ุงุฒ ุญุงูุช $s$ ุฏุฏู ูโุดูุฏ.
 \subsubsection{ุฑูุดโูุง Q-learning}
%\ูุณูุช{ุฑูุดโูุง Q-learning}

ุฎุงููุงุฏู ุฑูุดโูุง  Q-learning ุชูุงุด ูโฺฉููุฏ ูุณุชููุง ุชุงุจุน ุงุฑุฒุด ุนูู-ุญุงูุช ุจููู $Q^*(s,a)$ ุฑุง ุชุฎูู ุจุฒููุฏ. ุขูโูุง ุจู ุทูุฑ ูุนููู ุงุฒ ฺฉ ุชุงุจุน ูุฏู ูุจุชู ุจุฑ ูุนุงุฏูู ุจููู ุงุณุชูุงุฏู ูโฺฉููุฏ. ุงู ุจูููโุณุงุฒ ุชูุฑุจุงู ููุดู ุจู ุตูุฑุช off-policy ุงูุฌุงู ูโุดูุฏุ ุจู ุงู ูุนู ฺฉู ูุฑ ุจูโุฑูุฒุฑุณุงู ูโุชูุงูุฏ ุงุฒ ุฏุงุฏูโูุง ุฌูุนโุขูุฑ ุดุฏู ุฏุฑ ูุฑ ููุทู ุงุณุชูุงุฏู ฺฉูุฏุ ุจุฏูู ุงูฺฉู ุฏุฑ ูุธุฑ ุจฺฏุฑุฏ ูุญูู ุงูุชุฎุงุจ ุนุงูู ุจุฑุง ฺฉุดู ูุญุท ุฏุฑ ููฺฏุงู ุจูโุฏุณุช ุขูุฑุฏู ุฏุงุฏูโูุง ฺฺฏููู ุจูุฏู ุงุณุช. ุฎุทโูุด ูุฑุจูุทู ุงุฒ ุทุฑู ุงุฑุชุจุงุท ุจู 
$Q^*$
ู
$\pi^*$
 ุจูโุฏุณุช ูโุขุฏ. 
 ุนุงูู ุจุนุฏ ุงุฒ ุงุฏฺฏุฑูุชู ุชุงุจุน $Q_\theta(s,a)$ ุจู ุทูุฑโฺฉู  $Q_\theta(s,a) \approx Q^*(s,a)$ ูโุชูุงูุฏ ุนูู ุจููู ุฏุฑ ุญุงูุช $s$ ุฑุง ุจู ุจู ุตูุฑุช ุฒุฑ ูุญุงุณุจู ฺฉูุฏ $$a(s) = arg \max_a Q_{\theta}(s,a).$$
ุงุฒ ุฌููู ุงูฺฏูุฑุชูโูุง Q-learning ูโุชูุงู ุจู ููุงุฑุฏ ุฒุฑ ุงุดุงุฑู ฺฉุฑุฏ:
\begin{itemize}
\item ุฑูุด ฺฉูุงุณฺฉ DQN ฺฉู ุญูุฒู ุงุฏฺฏุฑ ุชููุช ฺุฑู\LTRfootnote{Deep reinforcement learning} ุฑุง ุนููุง ุงุฑุชูุง ุจุฎุดุฏ.
\item ุฑูุด C51 ฺฉู ุชูุฒุน ุฑู ุนุงุฏ ุฑุง ูโุขููุฒุฏ ฺฉู ุงูุฏุฑุงุถ ุขู $Q^*$ ุงุณุช.
\end{itemize}
\subsubsection{ุฑูุด DQN}
ุฑูุด DQN 
\ref{andrychowicz2017hindsight}
 ฺฉ ุงูฺฏูุฑุชู ุงุฏฺฏุฑ ุชููุช ุจุฏูู ูุฏู ุจุฑุง ูุถุง ุนูู ฺฏุณุณุชู ุงุณุช. ุฏุฑ ุงู ุฑูุดุ ุชุฎูู ุงุฒ ุชุงุจุน ุงุฑุฒุด ุนูู ุจููู $Q^*$ ูุญุงุณุจู ู\nf ุดูุฏ. ฺฉ ุดุจฺฉู ุนุตุจุ ฺฉู 
\textit{\ููู{ุดุจฺฉู Q}}\LTRfootnote{Q-network}
  ูุงูุฏู ู\nf ุดูุฏุ ุจู ุนููุงู ุชูุฑุจ\nf ฺฏุฑ ุชุงุจุน $Q^*$ ุงุณุชูุงุฏู ู\nf ุดูุฏ.
ุฏุฑ ุงุฒ ุฑูุดุ ฺฉู ฺฉ ุฑูุด ูุณุชูู ุงุฒ ุฎุท\nf ูุด ุงุณุชุ ุฏูุฑู\nf ูุง ุชูุณุท ฺฉ ุฎุท\nf ูุด 
\epsilon ุญุฑุตุงูู
ูุฑุจูุท ุจู ุชูุฑุจ ูุนู ุชุงุจุน ุงุฑุฒุดุ $Q$ุ ุชููุฏ ู\nf ุดูุฏ. ฺูุงุฑุชุง\nf ูุง ุงูุชูุงูุ
$s_t, a_t, r_t, s_{t+1}$
ฺฉู ุฏุฑ ุทูู ุขููุฒุด ุจู ูุฌูุฏ ู\nf ุขูุฏุ ุฏุฑ ุฌุง ุจู ูุงู
\textit{ุงูุจุงุฑ ุชฺฉุฑุงุฑ}\LTRfootnote{Replay Buffer}
ุฐุฎุฑู ู\nf ุดููุฏ. ุดุจฺฉู Q ุชูุณุท ุงูฺฏูุฑุชู ูุฒูู ฺฏุฑุงุฏุงู ุฑู ุชุงุจุน ูุฒูู 
$L_i$
ฺฉู ุชุงุจุน ุงุฒ ูพุงุฑุงูุชุฑูุง ุดุจฺฉูุ $\theta_i$ ุงุณุชุ ุฑู ฺฉ ููููู ุชุตุงุฏู ุงุฒ ุชุฌุฑุจุงุช ุฏุฑูู ุงูุจุงุฑ ุชฺฉุฑุงุฑุ ุขููุฒุด ุฏุงุฏู ู\nf ุดูุฏ.

ฺฉ ฺุงูุด ุฌุฏ ฺฉู ุฏุฑ ุงุณุชูุงุฏู ุงุฒ ุดุจฺฉู ุนุตุจ ุจุฑุง ุงุฏฺฏุฑ ุชููุช ูุฌูุฏ ุฏุงุฑุฏ ุงู ุงุณุช ฺฉู ุงุบูุจ ุงูฺฏูุฑุชู ูุง ุจููู ุณุงุฒุ ูุฑุถ ู ฺฉููุฏ ฺฉู ููููู ูุง ุจู ุทูุฑ ฺฉููุงุฎุช ู ูุณุชูู ุงุฒ ฺฉุฏฺฏุฑุ ุงุฒ ูุถุง ุฏุงุฏู ูุง ุงูุชุฎุงุจ ู ุดููุฏ. ุฏุฑุญุงูฺฉู ุฏุฑ ุงุฏฺฏุฑ ุชููุชุ ุงู ูุฑุถ ูุนูููุง ุจุฑูุฑุงุฑ ูุณุชุ ุจู ุฎุตูุต ุงฺฏุฑ ููููู ูุง ุงุฒ ุทุฑู ฺฉุงูุด ุฏุฑ ูุญุท ูุงูุน ุจู ุฏุณุช ุขูุฏู ุจุงุดุฏ. ฺฉ ุงุฒ ุฑูุด ูุง ุจุฑุง ุญู ุงู ูุดฺฉูุ ุงุณุชูุงุฏู ุงุฒ ุงูุจุงุฑ ุชุฌุฑุจู ุงุณุช. ุฏุฑ ูุฑ ฺฏุงูุ ุชุฌุฑุจู ุจู ุฏุณุช ุขูุฏู ุฑุง ุฏุฑ ุญุงูุธู ุง ุจู ูุงู ุงูุจุงุฑ ุชุฌุฑุจู ุฐุฎุฑู ู ฺฉูู. ูุฑ ุชุฌุฑุจู ุจู ุดฺฉู ฺูุงุฑุชุง $(s,a,r,s')$ ุฐุฎุฑู ู ุดูุฏ. ุงุฒ ุงูุจุงุฑ ุชุฌุฑุจู ู ุชูุงู ุจุฑุง ููููู ฺฏุฑ ู ุฏุณุชู \LTRfootnote{batch} ุณุงุฒ ุงุณุชูุงุฏู ฺฉุฑุฏ. ุงฺฏุฑ ุงูุจุงุฑ ุชุฌุฑุจู ูพุฑ ุดูุฏุ ฺฉููู ุชุฑู ุชุฌุฑุจุงุชุ ุญุฐู ู ุดููุฏ ุชุง ุชุฌุฑุจุงุช ุชุงุฒู ุฌุงฺฏุฒู ุขููุง ุดูุฏ

ุจุฑุง ูพุงุฏุงุฑ ุจุดุชุฑ ุฑููุฏ ุจููู ุณุงุฒุ $y_t$ ุจุง ุงุณุชูุงุฏู ุงุฒ 

ฯQ (s) = argmaxaโAQ (s ุ a). ุณุงุณุช ฺฏุฑุงูุจูุง w.r.t. Q ุณุงุณุช ุงุณุช ฺฉู ุงุญุชูุงู ุขู ุงุชุฎุงุฐ ู ุดูุฏ
ฺฉ ุนูู ุชุตุงุฏู (ุจู ุทูุฑ ฺฉููุงุฎุช ุงุฒ A ููููู ฺฏุฑ ุดุฏู) ู ุนูู ฯQ (ูุง) ุฑุง ุจุง ุงุญุชูุงู 1 - ุงูุฌุงู ู ุฏูุฏ.
ุฏุฑ ุทูู ุขููุฒุด ุ ูุง ูุณูุชูุง ุฑุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุณุงุณุช -ุจุฎูุฑุฏฺฏ w.r.t ุงุฌุงุฏ ู ฺฉูู. ุชูุฑุจ ูุนู ุงุฒ
ุชุงุจุน ุนูู-ููุฏุงุฑ Q. ููฺฉู ูุง ุงูุชูุงู (st ุ at ุ rt ุ st + 1) ฺฉู ุฏุฑ ุทูู ุขููุฒุด ุฏุฏู ู ุดููุฏ ุ ูุณุชูุฏ
ุฏุฑ ุจุงูุฑ ูพุฎุด ุจู ุงุตุทูุงุญ ุฐุฎุฑู ู ุดูุฏ. ูุณู ุงูพุฒูุฏูุง ุฌุฏุฏ ุจุง ุชุฑฺฉุจ ุนุตุจ ุชุฑฺฉุจ ู ุดูุฏ
ุขููุฒุด ุดุจฺฉู. ุงู ุดุจฺฉู ุจุง ุงุณุชูุงุฏู ุงุฒ ุดุจ ุดุจ ูู ุฏุณุชู ุง ุฏุฑ ุงุฒ ุฏุณุช ุฏุงุฏู L ฺฉู ุขููุฒุด ุฏุงุฏู ู ุดูุฏ
ุนููฺฉุฑุฏ Q ุชูุฑุจ ุฑุง ุจุฑุง ุฌูุจ ุฑุถุงุช ูุนุงุฏูู ุจููู ุชุดูู ู ฺฉูุฏ: L = E (Q (stุ at) - yt)
2
ุ
ฺฉู ุฏุฑ ุขู yt = rt + ฮณ maxa0โA Q (st + 1ุ a0
) ู ุงุฒ tuples (stุ atุ rtุ st + 1) ุงุฒ ูพุฎุด ููููู ุจุฑุฏุงุฑ ู ุดูุฏ
ุจุงูุฑ 1
.
ุจู ููุธูุฑ ุซุจุงุช ุจุดุชุฑ ุงู ุฑูุด ุจููู ุณุงุฒ ุ ูุนูููุงู ุงูุฏุงู ุจุง ุงุณุชูุงุฏู ุงุฒ a ูุญุงุณุจู ู ุดููุฏ
ุดุจฺฉู ูุฏู ุฌุฏุงฺฏุงูู ฺฉู ุจุง ุณุฑุนุช ฺฉูุชุฑ ูุณุจุช ุจู ุดุจฺฉู ุงุตู ุชุบุฑ ู ฺฉูุฏ. ฺฉ ุนูู ูุนููู
1 ุงูุฏุงู ุจู ูพุงุฑุงูุชุฑูุง ุดุจฺฉู ุจุณุชฺฏ ุฏุงุฑุฏ ุงูุง ุงู ูุงุจุณุชฺฏ ุฏุฑ ุท ุงูุชุดุงุฑ ูุฌุฏุฏ ูุงุฏุฏู ฺฏุฑูุชู ู ุดูุฏ.
2
ุจุฑุง ุชูุธู ุฏูุฑู ุง ูุฒู ุดุจฺฉู ูุฏู ุจุฑ ูุฒู ูุนู ุดุจฺฉู ุงุตู ุงุณุช (ุจู ุนููุงู ูุซุงู
ููู ู ููฺฉุงุฑุงู (2015)) ุง ุจุฑุง ุงุณุชูุงุฏู ุงุฒ ูุงูฺฏู polyak2
(Polyak ู Juditsky ุ 1992) ูุณุฎู ุงุตู
ุฏุฑ ุนูุถ ุดุจฺฉู (Lillicrap ู ููฺฉุงุฑุงู ุ 2015).

Deep Q-Networks (DQN) (Mnih et al., 2015) is a model-free RL algorithm for discrete action
spaces. Here we sketch it only informally, see Mnih et al. (2015) for more details. In DQN we
maintain a neural network Q which approximates Qโ
. A greedy policy w.r.t. Q is defined as
ฯQ(s) = argmaxaโAQ(s, a). An -greedy policy w.r.t. Q is a policy which with probability  takes
a random action (sampled uniformly from A) and takes the action ฯQ(s) with probability 1 โ .
During training we generate episodes using -greedy policy w.r.t. the current approximation of
the action-value function Q. The transition tuples (st, at, rt, st+1) encountered during training are
stored in the so-called replay buffer. The generation of new episodes is interleaved with neural
network training. The network is trained using mini-batch gradient descent on the loss L which
encourages the approximated Q-function to satisfy the Bellman equation: L = E (Q(st, at) โ yt)
2
,
where yt = rt + ฮณ maxa0โA Q(st+1, a0
) and the tuples (st, at, rt, st+1) are sampled from the replay
buffer1
.
In order to make this optimization procedure more stable the targets yt are usually computed using a
separate target network which changes at a slower pace than the main network. A common practice
1The targets yt depend on the network parameters but this dependency is ignored during backpropagation.
2
is to periodically set the weights of the target network to the current weights of the main network (e.g.
Mnih et al. (2015)) or to use a polyak-averaged2
(Polyak and Juditsky, 1992) version of the main
network instead (Lillicrap et al., 2015).
%\ูุณูุช*{ุฑูุด DQN}
ูุนูููุง ุจุฑุง ุชูุฑุจ ุฒุฏู ุชูุงุจุน ุงุฑุฒุด ุฏุฑ ุงุฏฺฏุฑ ุชููุชุ ุงุฒ ฺฉ ุชุงุจุน ุฎุท ุงุณุชูุงุฏู ูโุดูุฏ.
ุงูุง ฺฏุงู ุงููุงุช ุงุฒ ฺฉ ุชูุฑุจ ุนููฺฉุฑุฏ ุบุฑุฎุท ุจู ุฌุง ุขูุ ูุงููุฏ ฺฉ ุดุจฺฉู ุนุตุจ ูู ูโุชูุงู ุงุณุชูุงุฏู ฺฉุฑุฏ. ุดุจฺฉูโูุง ุนุตุจ ุจุง ุนููุงู ุดุจฺฉู Q\LTRfootnote{Q-Network} ุดูุงุฎุชู ูโุดููุฏ.
ุดุจฺฉู Q ุฑุง ูโุชูุงู ุจุง ฺฉููู ุณุงุฎุชู ุฏูุจุงููโุง ุงุฒ ุชูุงุจุน ูุฒูู ุจู ุดฺฉู 
$L_1(\theta_1), L_2(\theta_2), L_3(\theta_3), ... $ ุขููุฒุด ุฏุงุฏุ ุจู ุทูุฑโฺฉู
$$L_i(\theta_i)=\mathbb{E}\left[(y_i - Q(s,a;\theta_i))^2\right]$$  ู  $$y_i = \mathbb{E}[r + \gamma \max_{a'} Q(s',a'; \theta_{i-1})| s,a].$$ ุจุง ูุดุชู ฺฏุฑูุชู ุงุฒ ุชุงุจุน ูุฒูู ูุณุจุช ุจู ูพุงุฑุงูุชุฑูุง $\theta_i$  ุฎูุงูู ุฏุงุดุช: $$\nabla_{\theta_i} L_i{\theta_i} = \mathbb{E}\left[ \left(r + \gamma \max{a'} Q(s',a';\theta_{i-1}) - Q(s,a;\theta_i)\right) \nabla_{\theta_i} Q(s,a;\theta_i)\right].$$
%Rather than computing the full expectations in the above gradient, it is often computationally expedient to optimise the loss function by stochastic gradient descent. If the weights are updated after
%every time-step, and the expectations are replaced by single samples from the behaviour distribution
%ฯ and the emulator E respectively, then we arrive at the familiar Q-learning algorithm [26].
ุจู ุฌุง ูุญุงุณุจู ุงูุฏุฑุงุถ ฺฉุงูู ุฏุฑ ฺฏุฑุงุฏุงู ูููุ ุบุงูุจุงู ุงุฒ ูุธุฑ ูุญุงุณุจุงุชุ ุจูููโุณุงุฒ ุชุงุจุน ูุฒูู ุจุง ูุฒูู ฺฏุฑุงุฏุงู ุชุตุงุฏู  \LTRfootnote{stochastic gradient descend} ุฑุงูโุญู ุจูุชุฑ ุงุณุช. ุงฺฏุฑ ุฏุฑ ูุฑ ููุทุน ุฒูุงูุ ูุฒูโูุง ุจู ุฑูุฒุฑุณุงู ุดูุฏ ู ุงูุฏุฑุงุถ ุจุง ฺฉ ููููู ุงุฒ ุชูุฒุน ุฎุทโูุด ุฑูุชุงุฑ \LTRfootnote{behavior policy} ุฌุงฺฏุฒู ุดูุฏุ ุงูฺฏูุฑุชู
\ref{alg:qlearnn}
 Q-learning ุฑุง ูุดุงู ูโุฏูุฏ.
\ุดุฑูุน{ุงูฺฏูุฑุชู}
{ุงูฺฏูุฑุชู Q-learning ุจุง Experience replay}

\ุฏุณุชูุฑ{ุญุงูุธู 
	replay 
	$D$
ุฑุง ููุฏุงุฑ ุฏู ุงููู ฺฉู}
\ุฏุณุชูุฑ{ุชุงุจุน ุงุฑุฒุดู ุนูู Q ุฑุง ุจุง ูุฒูโูุง ุชุตุงุฏู ููุฏุงุฑุฏู ุงููู ฺฉู}
\ุจูโุงุฒุง{ุจุฑุง ูุฑ ุงูพุฒูุฏ 
$1...M$}
\ุฏุณุชูุฑ{ุฏูุจุงูู 
	$d_1 = \{S_1\}$
	 ู ฺฉุฏูฺฏ 
	 $\phi_1 = \phi(d_1)$
	  ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู}
\ุจูโุงุฒุง{ุจุฑุง $t=1...T$}
\ุฏุณุชูุฑ{ุจุง ุงุญุชูุงู $\epsilon$ ฺฉ ุนูู ุชุตุงุฏู $a_t$ ุฑุง ุงูุชุฎุงุจ ฺฉูุ ุฏุฑ ุบุฑ ุงู ุตูุฑุช 
	$a_t = \max_{a} Q^*(\phi(d_t),a;\theta)$
	 ุฑุง ุงูุชุฎุงุจ ฺฉู}
 \ุฏุณุชูุฑ{ุนูู $a_t$ ุฑุง ุงูุฌุงู ุจุฏู ู ุญุงูุช $S_{t+1}$ ู ูพุงุฏุงุด $R_t$ ุฑุง ูุดุงูุฏู ฺฉู}
 \ุฏุณุชูุฑ{ูุฑุงุฑ ุจุฏู 
 	$d_{t+1} = d_t,a_t,S_{t+1}$
 	 ู 
 	 $\phi_{t+1} = \phi(d_{t+1})$
  }
\ุฏุณุชูุฑ{ุชุฌุฑุจู 
	$(\phi_t, A_t, R_t, \phi_{t+1})$
	 ุฑุง ุฏุฑ $D$ ุฐุฎุฑู ฺฉู}
 \ุฏุณุชูุฑ{ฺฉ ููููู ุชุตุงุฏู ุงุฒ ุชุฌุฑูโูุง  
 	$(\phi(j), A_j, R_j, \phi_{j+1})$
 	ุงุฒ ุงูุจุงุฑ ุชุฌุฑุจุงุช $D$ ุงูุชุฎุงุจ ฺฉู}
 \ุฏุณุชูุฑ{ูุฑุงุฑ ุจุฏู 
 	\lr{
 	$y_j =$ 
 	\begin{cases}
 		$r_j$
 		 &
 		  $\phi_{j+1} \  terminal$ \\
 		$r_j$ & $otherwise$
 	\end{cases}}
}
\ุฏุณุชูุฑ{ฺฉ ฺฏุงู ุงุฒ ูุฒูู ฺฏุฑุงุฏุงู ุฑุง ุจุฑุง ุชุงุจุน ูุฒูู 
	$(y_j - Q(\phi_j, a_j; \theta))^2$
	 ุงูุฌุงู ุจุฏู}
  \ูพุงุงูโุจูโุงุฒุง
\ูพุงุงูโุจูโุงุฒุง
\label{alg:qlearnn}
\ูพุงุงู{ุงูฺฏูุฑุชู}
ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ุงูฺฏูุฑุชู \ref{alg:qlearnn} ฺฉ ุงูฺฏูุฑุชู ุจุฏูู ูุฏู ุงุณุช. ุงู ฺฉุงุฑ ูุธูู ุงุฏฺฏุฑ ุชููุช ุฑุง ูุณุชููุงู ุจุง ุงุณุชูุงุฏู ุงุฒ ูููููโูุง ุดุจู ุณุงุฒ E ุจุฏูู ุณุงุฎุชู ุตุฑุญ ุชุฎูู E ุญู ูโฺฉูุฏ.
\\ ุงุณุชุฑุงุชฺ ุญุฑุตุงููุ 
 $a = \max_{a} Q(s, a; \theta)$
 ุ ุฏุฑ ุญุงูโฺฉู ุงุฏ ูโฺฏุฑุฏ ฺฉู
ฺฉุงูุด ฺฉุงู ุฏุฑ ูุถุง ุญุงูุช ุฑุง ุชุถูู ฺฉูุฏ. ุชูุฒุน ุฑูุชุงุฑ ุงุบูุจ ุชูุณุท ฺฉ ุงุณุชุฑุงุชฺ Greed ุงูุชุฎุงุจ ูโุดูุฏ ฺฉู ุงุณุชุฑุงุชฺ ุญุฑุตุงูู ุฑุง ุจุง ุงุญุชูุงู 1 ุฏูุจุงู ูโฺฉูุฏ ู ฺฉ
ุงูุฏุงู ุชุตุงุฏู ุจุง ุงุญุชูุงู $\epsilon$
!!!!!!!!!!!!!!
\subsubsection{ุฑูุด C51 }
\begin{align}
Q^*(x,a)= \mathbb{E} R(x,a)+\gamma \mathbb{E}_P \max_{a' \in \EuScript{A}} Q^* (x',a').
\label{eq:Q^*}
\end{align}
ุฏุฑ ูุนุงุฏูู \ref{eq:Q^*} $Q^*$ ููุทู ุซุงุจุช ููุญุตุฑ ุจู ูุฑุฏ ุงุณุชุ ุชุงุจุน ุงุฑุฒุด ุจูููุ ฺฉู ูุฑุจูุท ุงุณุช ุจู ูุฌููุนู ุฎุทโูุดโูุง ุจููู 
$\Pi^*$
($\pi*$ ุจููู ุงุณุช ุงฺฏุฑ
$\mathbb{E}_{a\sim \pi^*} Q^*(x,a) = \max_{a}Q^*(x,a).$)

ุชุงุจุน ุงุฑุฒุด ู ุชุงุจุน ูพุงุฏุงุด ฺุดูุฏุงุดุช ุฑุง ุจุฑุฏุงุฑูุง ุฏุฑ ูุถุง 
$\mathbb{R}^{\EuScript{X \times A}}$ 
ุฏุฑ ูุธุฑ ูฺฏุฑู. ุฏุฑ ุงู ุญุงูุช ุนููฺฏุฑ ุจูููุ $\EuScript{T}^\pi$ุ ู ุนููฺฏุฑ ุจููู $\EuScript{T}$ ุจู ุดฺฉู ุฒุฑ ุงุณุช:
\begin{align}
\EuScript{T}^\pi Q(x,a) := \mathbb{E} R(x,a) + \gamma \mathbb{E}_{P,\pi} Q(x',a') \\
\EuScript{T} Q(x,a) := \mathbb{E} R(x,a) + \gamma \mathbb{E}_P \max_{a' \in \EuScript{A}} Q(x',a')
\end{align}
ุนููฺฏุฑ ุจููู ู ุนููฺฏุฑ ุจูููุ ุจู ุทูุฑ ุฎุงุตุ ูุฑุฏู ูฺฏุงุดุช ุงููุจุงุถ ูุณุชูุฏ ู ุงุนูุงู ูฺฉุฑุฑ ุขููุง ุฑู ฺฉ $Q_0$ ุงูููุ ุจู ุตูุฑุช ููุง ุจู ุชุฑุชุจ ุจู $Q^\pi$ ู $Q^*$ ููฺฏุฑุง ูโุดูุฏ
\cite{bertsekas1996neuro}.
 ุงูุฏ ุฑุงุถ ุงุฒ ูุนุงุฏูู ุจููู ุจุฑูู ฺฉุดุฏู ูโุดูุฏ ู ุฏุฑ ุนูุถ ฺฉ ุชูุฒุน ฺฉุงูู ุงุฒ ูุชุบุฑ ุชุตุงุฏู 
$Z^\pi$ 
ูุฑุงุฑ ุฏุงุฏู ูโุดูุฏ ฺฉู ูฺฏุงุดุช ุงุฒ ุฏูุชุง ุญุงูุช ุนูู ุจู ุชูุฒุน ุงุฒ ุนุงุฏโูุง ุงุณุช. ุชุงุจุน 
$Z^\pi$ 
 ุชูุฒุน ุงุฑุฒุด ูโโุจุงุดุฏ.
\ุดุฑูุน{ุชุนุฑู}
ุจุฑุง 
$F$
 ู 
 $G$
ฺฉู ุฏู ุชุงุจุน ุชูุฒุน ุชุฌูุน ุจุฑ ุฑู ุงุนุฏุงุฏ ุญูู ูุณุชูุฏุ ุชุนุฑู ูโุดูุฏ.
\begin{align}
d_p (F,G):= \inf_{U,V} \parallel U-V \parallel_{p},
\label{eq:inf}
\end{align}
ฺฉู ุงูููู ุฑู ุชูุงู ุฌูุช ูุชุบุฑูุง ุชุตุงุฏู  
 $(U,V)$
  ฺฉู ุชุงุจุน ุชูุฒุน ุชุฌูุน ูุฑุจูุท ุจู ุขูโูุง ุจู ุชุฑุชุจ 
 $F$
 ู 
 $G$
 ุจุงุดุฏุ ฺฏุฑูุชู ูโุดูุฏ.
 ุงูููู ุชูุณุท ุชุจุฏู ูุนฺฉูุณ ุชุงุจุน ุชูุฒุน ุชุฌูุน ุฑู ฺฉ ูุชุบุฑ ุชุตุงุฏู 
 $\EuScript{u}$
 ุจุง ุชูุฒุน ฺฉููุงุฎุช ุฏุฑ ุจุงุฒู 
 $[0,1]$
 ุญุงุตู ูโุดูุฏ:
 $$d_p (F,G) = \parallel F^{-1}(\EuScript{U})-G^{-1} (\EuScript{U})\parallel_{p}$$
 ุจุฑุง 
$p < \infty$
ูโุชูุงู ููุดุช:
$$d_p (F,G) = \left( \int_{0}^{1} \mid F^{-1}(u)-G^{-1} (u)\mid^{p} du \right)^{1/p}$$
ุจุง ุฏุงุดุชู ุฏู ูุชุบุฑ ุชุตุงุฏู 
$(U,V)$
ุจุง ุชูุงุจุน ุชูุฒุน ุชุฌูุน 
$F_U,F_V$
ูโุชูุงู ููุดุช
$$d_p(U,V) := d_p(F_U,F_V)$$
 ูโุชูุงู ุจุง ูุฑุงุฑ ุฏุงุฏู ุฎูุฏ ูุชุบุฑโูุง
   $U$ ู $V$
     ุจู ุฌุง ุชูุงุจุน ุชูุฒุน ุชุฌูุนโุดุงู ุฏุฑ ูุฑููู 
     \ref{eq:inf}
      ุจู ุทูุฑ ุณุงุฏู ุชุฑ ููุดุช:
$$d_p(U,V)= \inf_{U,V} \parallel U-V\parallel_p$$ 
\ูพุงุงู{ุชุนุฑู}

\ุดุฑูุน{ุชุนุฑู}
\EuScript{Z} 
ูุถุง ุชูุฒุน ุงุฑุฒุด ุจุง ููุงูโูุง
\LTRfootnote{Moment}
 ูุญุฏูุฏ ุชุนุฑู ูโุดูุฏ.
ุจุฑุง ุฏู ุชูุฒุน ุงุฑุฒุด 
$Z_1$
ู
$Z_2$
ุนุถู 
\EuScript{Z} 
ุงุฒ ูุฑู ูุงฺฉุณูุงู ูุชุฑฺฉ ูุงุณุฑุดุชุงู
\LTRfootnote{Wasserstein}
ุงุณุชูุงุฏู ูโฺฉูู:
$$\bar{d_p}(Z_1,Z_2) := \sup_{x,a} d_p(Z_1(x,a),Z_2(x,a))$$
ุงุฒ 
$\bar{d_p}$
ุจุฑุง ููฺฏุฑุง ุนููฺฏุฑูุง ุชูุฒุน ุจููู
\LTRfootnote{Distributional Bellman Operators}
 ุงุณุชูุงุฏู ูโุดูุฏ.
\ูพุงุงู{ุชุนุฑู}
\paragraph{ุงุฑุฒุงุจ ุฎุทโูุด}
ุฏุฑ ุฑููุฏ ุงุฑุฒุงุจ ุฎุทโูุดุ ูุทููุจ ุงุณุช ุชุงุจุน ุงุฑุฒุด
$V^\pi$
ูุฑุชุจุท ุจุง ุฎุทโูุดู $\pi$ ุฏุงุฏู ุดุฏู. 
ุชุงุจุน ูพุงุฏุงุด ุจู ุนููุงู ฺฉ ุจุฑุฏุงุฑ ุชุตุงุฏูุ 
$R \in \EuScript{Z}$ุ
ูุนููฺฏุฑ ุงูุชูุงู ุชุนุฑู ูโุดูุฏุ
$P^\pi : \EuScript{Z} \rightarrow \EuScript{Z}$
\begin{align}
P^{\pi} Z(x,a) := Z(X',A') \\ \numberthis
X' \sim P(.|x,a), A'\sim \pi (.|X'), \nonumber
\end{align}
ุนููฺฏุฑุชูุฒุน ุจูููุ
$\EuScript{T}^\pi : \EuScript{Z} \rightarrow \EuScript{Z}$ุ
 ุฏุฑ ูุธุฑ ฺฏุฑูุชู ูโุดูุฏ:
\begin{align}
 \EuScript{T}^\pi Z(x,a) := R(x,a)+ \gamma P^\pi Z(x,a)
\end{align}  
ูโุชูุงู ูุดุงู ุฏุงุฏ ฺฉู $T^\pi$ ฺฉ ูฺฏุงุดุช ุงููุจุงุถ 
\LTRfootnote{Contraction Mapping}
ุฑู
 $Z$
  ุงุณุช ฺฉู ููุทู ุซุงุจุช ุขู ุชูุฒุน ุงุฑุฒุด 
$Z^\pi$
    ุงุณุช.
ุงฺฏุฑ 
$\Pi^*$
ูุฌููุนูโุง ุงุฒ ุฎุทโูุดโูุง ุจููู ุจุงุดุฏ. 
ุชุงุจุน ุชูุฒุน ุงุฑุฒุด ุจููู ุชุนุฑู ูุดูุฏ:
\ุดุฑูุน{ุชุนุฑู}
ุชูุฒุน ุงุฑุฒุด ุจูููุ ุชุงุจุน ุชูุฒุนู ุงุฑุฒุด ุฎุทโูุดู ุจููู ุงุณุช. ูุฌููุนู ุชูุฒุน ุงุฑุฒุดโูุง ุจููู ุชุนุฑู ูโุดููุฏ:
$$\EuScript{Z}^* := {Z^{\pi^{*}} : \pi^* \in \Pi^* }$$
ุชุงฺฉุฏ ูโุดูุฏ ฺฉู ููู ุชูุฒุน ุงุฑุฒุดโูุง ุจุง ููุฏุงุฑ ฺุดูุฏุงุดุช $Q^*$ 
ุจููู ูุณุชูุฏุ ุชููุง ุฏุฑ ุตูุฑุช ุจููู ูุณุชูุฏ ฺฉู ูุทุงุจู ุจุง ุชูุฒุน ฺฉุงูู ุนุงุฏ ุจุฑโุงุณุงุณ ุฎุทโูุด ุจููู ุจุงุดูุฏ.
\ูพุงุงู{ุชุนุฑู} 
\ุดุฑูุน{ุชุนุฑู}
ุฎุทโูุด ุญุฑุตุงูู
$\pi$
ุจุฑุง
$Z \in \EuScript{Z}$
ููุฏุงุฑ ฺุดูุฏุงุดุช
$Z$
 ุฑุง ุจุดูู ูโฺฉูุฏ.
 ูุฌููุนู ุฎุทโูุดโูุง ุญุฑุตุงูู ุจุฑุง 
 $Z$
 ุจู ุงู ุดฺฉู ุชุนุฑู ูโุดููุฏ:
 $$\EuScript{G}_Z := \lbrace \pi : \sum_{a} \pi (a|x) \ \mathbb{E} \ Z(x,a) = \max_{a' \in \EuScript{A}} \ \mathbb{E} \ Z(x,a') \rbrace.$$
\ูพุงุงู{ุชุนุฑู}

\ุดุฑูุน{ุชุนุฑู}
ฺฉ ุชูุฒุน ุงุฑุฒุด ุจููู ูุงูพุงุฏุงุฑุ
$Z^{**}$ุ
ุชูุฒุน ุงุฑุฒุดโ ุงุณุช ฺฉู ูุฑุจูุท ุจู ุฏูุจุงูู ุฎุทโูุดโูุง ุจููู ุงุณุช. ุจู ูุฌููุนูโุง ุงุฒ ุชูุฒุน ุงุฑุฒุดโูุง ุจููู ูุงูพุงุฏุงุฑ 
 $\EuScript{Z}^{**}$
 ฺฏูุชู ูโุดูุฏ.
\ูพุงุงู{ุชุนุฑู}

\ุดุฑูุน{ูุถู}
ูุฑุถ ูโุดูุฏ 
$\EuScript{X}$
ูุงุจู ุงูุฏุงุฒูโฺฏุฑ ู 
$\EuScript{A}$
ูุญุฏูุฏ ุจุงุดุฏ.
ุจูุงุจุฑุงู:
$$\lim_{k\to\infty} \inf_{Z^{**} \in \EuScript{Z}^{**}} d_p (Z_k (x,a), Z^{**}(x,a)) = 0  \ \forall x,a.$$
\ูพุงุงู{ูุถู}

\subsubsection{ ุฑูุด SAC}
ูุดุงู ุฏุงุฏู ูโุดูุฏ ฺฉู ูโุชูุงู ุงูฺฏูุฑุชู ุจุงุฒฺฏุฑ-ููุชูุฏ ุจุดูู ุขูุชุฑููพ ูุณุชูู ุงุฒ ุฎุท ูุดุ ฺฉู ุจุงุฒฺฏุฑ-ููุชูุฏ ูุฑู
\LTRfootnote{Soft Actor Critic(SAC)}
  ูุงูุฏูโ ูโุดูุฏ ุฑุง ุทุฑุงุญ ฺฉุฑุฏ.
ุงู ุงูฺฏูุฑุชู ุจู ุณุงุฏฺฏ ุจู ฺฉุงุฑูุง ุจุณุงุฑ ูพฺุฏู ุจุง ุงุจุนุงุฏ ุจุงูุง ุจุณุท ุฏุงุฏู ูโุดูุฏุ ุฌุง ฺฉู ุฑูุดโูุง ูุณุชูู ุงุฒ ุฎุท ูุดโ ูุงููุฏ
 $DDPG$
  ูุนูููุง ุจุฑุง ุฑุณุฏู ุจู ูุชุงุฌ ููุงุณุจุ ุจุง ฺุงูุด ุฑูุจูโุฑู ูุณุชูุฏ.
  
ุงุฏฺฏุฑ ุฎุทโูุด ุฏุฑ ูุถุงูุง ุนูู ูพูุณุชู ุขุฏุฑุณโุฏู ูโุดูุฏ. ฺฉ ูุฑุงูุฏ ุชุตููโฺฏุฑ ูุงุฑฺฉูู ุงูู-ุจโููุงุช
\LTRfootnote{Infinite Horizon Markov Decision}
 ุฏุฑ ูุธุฑ ฺฏุฑูุชู ูโุดูุฏ ฺฉู ุฏุฑ ุขู ูุถุง ุญุงูุช
  $S$
   ู ูุถุง ุนูู
   $A$
    ูพูุณุชู ูุณุชูุฏ.
ฺฉ ููุงุณ ุนููฺฉุฑุฏ ุนูููโุชุฑ ุจุดูู ุขูุชุฑููพ ุจุฑุฑุณ ุฎูุงูุฏ ุดุฏ.
ุจู ุนููุงู ูุซุงู ุจุจูุฏ: 
!!!!!!!!!!!!!!!!
ฺฉู ุจุง ุชููุช ููุงุณ ุนููฺฉุฑุฏ ุขูุชุฑููพ ฺุดูโุฏุงุดุช ุฎุทโูุด ุจู ููุน ุฎุทโูุดโูุง ุชุตุงุฏู ุนูู ูโฺฉูุฏ.
\begin{align}
J_{(\pi)}= \sum\limits_{t=0}^T \mathbb{E}_\pi \left[ r(s_t , a_t) + \alpha \EuScript{H} (\pi(.|s_t)) \right]
\label{eq:jpi}
\end{align}
ูโุชูุงู ุงูฺฏูุฑุชู ุจุงุฒฺฏุฑ-ููุชูุฏ ูุฑู ูุณุชูู ุงุฒ ุฎุทโูุด ุฑุง ุจุง ุดุฑูุน ุงุฒ ููุน ุฏฺฏุฑ ุงุฒ ูุชุฏ ุชฺฉุฑุงุฑ ุฎุทโูุดู ุจุดูู ุขูุชุฑููพ ุงุณุชุฎุฑุงุฌ ฺฉุฑุฏ.
ุจุง ุจูโุฏุณุช ุขูุฑุฏู ุชฺฉุฑุงุฑ ุฎุทโูุด ูุฑู ุดุฑูุน ุฎูุงูุฏ ุดุฏุ ฺฉู ฺฉ ุงูฺฏูุฑุชู ุนููู ุจุฑุง ุงุฏฺฏุฑ ุฎุทโูุดโูุง ุจุดูู ุขูุชุฑููพ ุจููู ฺฉู ุฏุฑ ฺุงุฑฺูุจ ุจุดูู ุขูุชุฑููพ ุจู ุงุฑุฒุงุจ ู ุจูุจูุฏ ุฎุทโูุด ุฏุฑ ุญุงู ุชูุงูุจ ุงุณุช.
ุฏุฑ ฺฏุงู ุงุฑุฒุงุจ ุฎุทโูุด ุงูุฏ ุงุณุช ููุฏุงุฑ ุฎุทโูุด
$\pi$
 ุจุฑุงุณุงุณ ููุงุณ ุนููฺฉุฑุฏ ุจุดูู ุขูุชุฑููพ ุฏุฑ ูุนุงุฏูู \ref{eq:jpi} ูุญุงุณุจู ุดูุฏ. ุจุฑุง ฺฉ ุฎุทโูุด ุซุงุจุชุ ููุฏุงุฑ $Q$  ูุฑู ูโุชูุงูุฏ ุจู ุตูุฑุช ฺฏุงูโุจูโฺฏุงู ุจุง ุดุฑูุน ุงุฒ ูุฑ ุชุงุจุน
  $Q:S \times R \rightarrow R$ 
 ู ุงุนูุงู ูฺฉุฑุฑ ฺฉ ุนููฺฏุฑ ูพุดุชุจุงู ุจููู ุงุตูุงุญ ุดุฏูุ
 $\EuScript{T}^\pi$
  ฺฉู ุฏุฑ ุชุงุจุน ุงุฑุฒุด ุญุงูุช ูุฑู ุจู ุตูุฑุช ุฒุฑ ุฏุงุฏู ุดุฏู ุงุณุชุ ูุญุงุณุจู ุดูุฏ:
\begin{align}
\EuScript{T}^\pi Q(s_t,a_t) \triangleq r(s_t,a_t)+\gamma \mathbb{E} \left[ V(s_t+1) \right]
\label{eq:tpi}
\end{align}
\begin{align}
V(s_t)= \mathbb{E}_\pi \left[ Q(s_t,a_t)- \log \pi(a_t | s_t) \right]
\end{align}
ูโุชูุงู ุชุงุจุน ุงุฑุฒุด ูุฑู ุจุฑุง ูุฑ ุฎุทโูุด$\pi$ ุฑุง ุจุง ุงุนูุงู ูฺฉุฑุฑุ $T^\pi$ ุจูโุฏุณุช ุขูุฑุฏ.
\begin{align}
\pi_{new} = arg \min_{\pi' \in \Pi} D_{KL}  \left( \pi'(.|s_t) \parallel \frac{\exp{(Q^{\pi_{old}} (s_t,.))}}{Z^{\pi_{old}} (s_t)}\right)
\label{eq:pinew}
\end{align}
ุชุงุจุน ูพุงุฑุด 
$Z^\pi (s_t)$
ุชูุฒุน ุฑุง ฺฉููุงุฎุช ูโฺฉูุฏ ู ุงุฒ ุขูุฌุง ฺฉู ุฏุฑ ุญุงูุช ุนููู ุบุฑูุงุจู ุญู ุงุณุชุ ุจู ฺฏุฑุงุฏุงู ูุณุจุช ุจู ุฎุทโูุด ุฌุฏุฏ ฺฉูฺฉ ููโฺฉูุฏ ู ุจู ููู ุฏูู ูโุชูุงูุฏ ูุงุฏุฏู ฺฏุฑูุชู ุดูุฏ. ุจุฑุง ุงู ุชุงุจุน ูโุชูุงู ูุดุงู ุฏุงุฏ ฺฉู ุฎุทโูุด ุฌุฏุฏ ูุณุจุช ุจู ุฎุทโูุด ูุฏู ุจุง ุชูุฌู ุจู ููุงุณ ุนููฺฉุฑุฏ ูุนุงุฏููโ \ref{eq:jpi} ููุฏุงุฑ ุจุดุชุฑ ุฏุงุฑุฏ. 
ุงูฺฏูุฑุชู ุชฺฉุฑุงุฑ ุฎุทโูุด ูุฑู ฺฉุงููุ ุจู ุงุฑุฒุงุจ ุฎุทโูุด ูุฑู ู ุจูุจูุฏ ุฎุทโูุด ูุฑู ุฏุฑ ุชูุงูุจ ุงุณุช ู ุฏุฑ ูุงู ุฎุทโูุดโูุง ุนุถู
$\Pi$ุ
ุงุญุชูุงูุง ุจู ุฎุทโูุด ุจุดูู ุขูุชุฑููพ ุจููู ููฺฏุฑุง ูโุดูุฏ.
 \paragraph{ุจุงุฒฺฏุฑ-ููุชูุฏ ูุฑู}
ุจูโุฏุณุช ุขูุฑุฏู ฺฉ ุชูุฑุจ ุชุฌุฑุจ ุจุฑุง ุชฺฉุฑุงุฑ ุฎุทโูุด ูุฑู ุฏุฑ ุฏุงูููโูุง ูพูุณุชูโ ุจุฒุฑฺฏ ููุฑุฏูุงุฒ ุงุณุช.  ุฏุฑ ุงูุชูุงุ ุชูุฑุจโฺฏุฑูุง ุชุงุจุน ุจุฑุง ุชุงุจุน
$ Q$
 ู ุฎุทโูุด ุงุณุชูุงุฏู ุฎูุงููุฏ ุดุฏ ุจู ุฌุง ุงุฌุฑุง ุจูุจูุฏ ู ุงุฑุฒุงุจ ุจุฑุง ููฺฏุฑุงุ ุจู ุจูููโุณุงุฒ ูุฑ ุฏู ุดุจฺฉู ุจุง ูุฒูู ฺฏุฑุงุฏุงู ุชุตุงุฏู ุฏุฑ ุชูุงูุจ ุงุณุช. ุชุงุจุน ููุฏุงุฑ ุญุงูุช ูพุงุฑุงูุชุฑ ุดุฏู
 $V_\psi (s_t)$
 ุ ุชุงุจุน$Q$ ูุฑู 
 $Q_\theta (s_t,a_t)$
  ู ุฎุทโูุด ูุงุจู ุญู 
  $\pi_\phi (a_t | s_t)$
  ุจุฑุฑุณ ุฎูุงููุฏ ุดุฏ. ูพุงุฑุงูุชุฑูุง ุงู ุดุจฺฉูโูุง 
  $\psi, \theta, \phi$
   ูุณุชูุฏ. ุจู ุนููุงู ูุซุงูุ ุชูุงุจุน ุงุฑุฒุด ูโุชูุงููุฏ ุจู ุนููุงู ุดุจฺฉูโูุง ุนุตุจ ฺฏูุง ู ุฎุทโูุด ุจู ุนููุงู ฺฉ ฺฏูุณ ุจุง ูุงูฺฏู ู ููฺฏุฑุง ฺฏุฑูุชู ุดุฏู ุงุฒ ุดุจฺฉูโูุง ุนุตุจุ ูุฏู ุดููุฏ.
ุชุงุจุน ุงุฑุฒุด ูุฑู ุจุฑุง ฺฉููู ฺฉุฑุฏู ูุฑุจุน ุฎุทุง ุจุงููุงูุฏูโูุง ุขููุฒุด ุฏุฏู ุดุฏูโุงุณุช.
ฺฉู 
$\EuScript{D}$
 ุชูุฒุน ุญุงูุชโูุง ู ุนููโูุง ูููููโฺฏุฑ ุดุฏู ูุจู ุง ุงูุจุงุฑ ุชุฌุฑุจู
 \LTRfootnote{Replay Buffer}
  ุงุณุช.
\begin{align}
\hat{\nabla}_\psi J_V (\psi) = \nabla_\psi V_\psi (s_t) (V_\psi (s_t)-Q_\theta(s_t,a_t)+\log \pi_\phi (a_t |s_t)) ,
\end{align}
ุนููโูุง ุจู ุฌุง ุงูุจุงุฑ ุชุฌุฑุจูุ ุจุฑุงุณุงุณ ุฎุทโูุด ูุนู ูููููโฺฏุฑ ุดุฏูโุงูุฏ. ูพุงุฑุงูุชุฑูุง ุชุงุจุน $Q$ ูุฑู ูโุชูุงูุฏ ุจุฑุง ฺฉููู ฺฉุฑุฏู ุจุงููุงูุฏูโ ุจููู ุขููุฒุด ุฏุฏูโุดูุฏ.
\begin{align}
J_Q(\theta) = \mathbb{E}_{\EuScript{D}} \left[ \frac{1}{2} \left( Q_\theta (s_t,a_t)- \hat{Q} (s_t,a_t)\right)^2 \right] ,
\end{align}
ุจุง 
\begin{align*}
\hat{Q} (s_t,a_t) = r(s_t,a_t) + \gamma \mathbb{E} [V_\Psi (s_t+1)] ,
\end{align*}
ฺฉู ูโุชูุงูุฏ ูุฌุฏุฏุง ุจุง ฺฏุฑุงุฏุงูโูุง ุชุตุงุฏู ุจููู ุดูุฏ.
\begin{align}
\hat{\nabla_{\theta}} J_Q (\theta) = \nabla_\theta Q_\theta (a_t,s_t) \left( Q_\theta (s_t,a_t)- r(s_t,a_t) - \gamma V_\Psi (s_t+1) \right). 
\label{eq:hatnabla}
\end{align}
ุฏุฑ ุขุฎุฑุ ูพุงุฑุงูุชุฑูุง ุฎุทโูุด ูโุชูุงููุฏ ุจุง ฺฉููู ฺฉุฑุฏู ูุณุชูู ููฺฏุฑุง-KL ฺุดูุฏุงุดุช ุฏุฑ ูุนุงุฏูู \ref{eq:pinew} ุขููุฎุชู ุดููุฏ:
\begin{align}
J_\pi(\phi) = \mathbb{E}\left[ D_{KL}  \left( \pi_\phi(.|s_t) \parallel \frac{\exp{(Q_{\theta} (s_t,.))}}{Z_{\theta} (s_t)}\right) \right]
\end{align}
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\ุดุฑูุน{ุงูฺฏูุฑุชู}{ุงูฺฏูุฑุชู $Policy Iteration$ ุจุง ููุงุณ ุนููฺฉุฑุฏ $L_\pi$}
\ุฏุณุชูุฑ{ุฎุทโูุด $\pi_0$
	ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู
}
$a_t \approx \pi_\phi(a_t|s_t)$ \\
$s_{t+1} \approx p(s_{t+1}|s_t,a_t)$\\
$\EuScript{D}\leftarrow \EuScript{D} \bigcup {(s_t,a_t,r(s_t,a_t),s_{t+1})}$ \\
$\psi \leftarrow \psi - \landa_V \hat{\nabla}_\spi J_V (\psi)$ \\
$\theta_i \leftarrow \theta_i - \landa_Q \hat{\nabla}_{\theta_i} J_Q(\theta_i) for i \in {1,2}$\\
$\phi \leftarrow \phi - \landa_\pi \hat{\nabla}_\phi J_\pi (Q)$ \\
$\bar{\psi} \leftarrow \tau \psi + (1-\tau) \psi$
\ูพุงุงู{ุงูฺฏูุฑุชู}
ฺฉู \ref{eq:hatnabla} ฺฉ ุจุฑุฏุงุฑ ููุฒ ูุฑูุฏ ุงุณุช ฺฉู ุงุฒ ฺฉ ุชูุฒุน ุซุงุจุช ูุงููุฏ ฺฉ ฺฏูุณ ฺฉุฑู ูููููโฺฏุฑ ุดุฏูโุงุณุช.
\subsubsection{ุฑูุด DDPG}
ฺฏุณุณุชู ุณุงุฒ ูุถุง ุนูู ฺฉ ุฑูุด ุจุฑุง ุณุงุฒฺฏุงุฑโฺฉุฑุฏู ู ุงูุทุจุงู ุฑูุดโูุง ุงุฏฺฏุฑ ุชููุช ุนูู ูุธุฑ 
\lr{DQN}
ุจุง ุฏุงูููโูุง ูพูุณุชู ูโุจุงุดุฏ. ุจุง ุงู ุญุงูุ ุงู ุฑูุด ูุญุฏูุฏุชโูุง ุฒุงุฏ ุฏุงุฑุฏุ ูุฎุตูุตุง ูุดฺฉู ููุฑู ุงุจุนุงุฏ. ููุฑู ุงุจุนุงุฏ ุจุงูโฺฏุฑ ุงู ุงุณุช ฺฉู ุชุนุฏุงุฏ ุนููโูุง ุจู ุตูุฑุช ููุง ุจุง ุชุนุฏุงุฏ ุฏุฑุฌุงุช ุขุฒุงุฏ ุงูุฒุงุด ูพุฏุง ูโฺฉูุฏ. 
ุฏุฑ ุฑูุด ุฌุฏุฏ ฺฉ ุงูฺฏูุฑุชู ุจุงุฒฺฏุฑ-ููุชูุฏ ูุณุชูู ุงุฒ ุฎุทโูุดุ ูุณุชูู ุงุฒ ูุฏู
\LTRfootnote{A model-free, off-policy actor-critic algorithm}
ุจุง ุงุณุชูุงุฏู ุงุฒ ุชุฎููโฺฏุฑ ุชุงุจุน ุนูู ุงุฑุงุฆู ูโุฏููุฏ ฺฉู ูโุชูุงูุฏ ุฎุทโูุดโูุง ุฑุง ุฏุฑ ูุถุงูุง ุนูู ูพูุณุชู ุจุง ุงุจุนุงุฏ ุจุงูุง ุงุฏ ุจฺฏุฑุฏ.
ุงู ุฑูุด ุจุฑ ุงุณุงุณ ุงูฺฏูุฑุชู ฺฏุฑุงุฏุงู ุฎุทโูุด ูุนู
\LTRfootnote{Deterministic policy gradient (DPG)}
ุงุณุช ฺฉู ุขู ุฑุง ฺฏุฑุงุฏุงู ุฎุทโูุด ูุนู ุนูู
\LTRfootnote{Deep DPG (DDPG)} 
ูโูุงูู. 
%Here we combine the actor-critic approach with insights from Deep Q Network (DQN)
ุฏุฑ ุขู ุฑูุดุ ุฑูฺฉุฑุฏ ุจุงุฒฺฏุฑ-ููุชูุฏ ุฑุง ุจุง ุจูุด ุดุจฺฉู \lr{Q} ุนูู
\LTRfootnote{Deep Q Network (DQN)} 
ุชุฑฺฉุจ ูโฺฉูู.
ุงูฺฏูุฑุชู 
\lr{DPG}
ุชุงุจุน ุนูู ูพุงุฑุงูุชุฑ
$
\mu (s|\theta^\mu)	
$
ุฑุง ูฺฏูุฏุงุฑ ูโฺฉูุฏ ฺฉู ุจุง ูฺฏุงุดุช ูุนู ุญุงูุชโูุง ุจู ฺฉ ุนูู ุฎุงุตุ ุณุงุณุช ูุนู ุฑุง ูุดุฎุต ูโฺฉูุฏ.
ููุงููุฏ ุฑูุด ุงุฏฺฏุฑ 
\lr{Q}
ุฏุฑ ุงูุฌุง ูุฒ ููุชูุฏ
$Q(s,a)$
ุจุง ุงุณุชูุงุฏู ุงุฒ ูุนุงุฏูู ุจููู ุขููุฎุชู ูโุดูุฏ.
%the actor is updated by following applying the chain rule to the expected return from the start distribution with respect to the actor parameters 
ุจุงุฒฺฏุฑ ุจุง ูพุฑู ุงุฒ ุงุนูุงู ูุงุนุฏู ุฒูุฌุฑูโุง ุฑู ุนุงุฏ ฺุดูโุฏุงุดุช ุงุฒ ุชูุฒุน ุดุฑูุน
$J$
ูุณุจุช ุจู ูพุงุฑุงูุชุฑูุง ุจุงุฒฺฏุฑ ุจูโุฑูุฒ ูโุดูุฏ.
\begin{align}
	\nabla_{\theta \mu} J = & \mathbb{E}_{s_t \sim \rho ^{ \beta}} [ \nabla_{\theta \mu} Q(s,a|\theta^Q)|_{s=s_t,a=\mu (s_t|\theta^{\mu})}  ] \\ \nonumber
	= & \mathbb{E}_{s_t \sim \rho ^{ \beta}} [ \nabla_{\theta \mu} Q(s,a|\theta^Q)|_{s=s_t, a=\mu (s_t)} \nabla_{\theta_{\mu}} \mu (s|\theta^{\mu})|_{s=s_t} ]
\end{align}
ุฏุฑ ุงู ุฑูุด ูุฒุ ูุงููุฏ ุฑูุด 
\lr{DQN}
ุงุฒ ุงูุจุงุฑ ุชุฌุฑุจู ุงุณุชูุงุฏู ูโุดูุฏ. 
ุฏุฑ ูุฑ ูุฑุญููุ ุจุงุฒฺฏุฑ ู ููุชูุฏ ุจุง ูููููโุจุฑุฏุงุฑ ฺฉููุงุฎุช ุงุฒ ุงูุจุงุฑ ุจูโุฑูุฒุฑุณุงู ูโุดููุฏ. ุงุฒ ุขูุฌุง ฺฉู 
\lr{DDPG}
ุงูฺฏูุฑุชู ูุณุชูู ุงุฒ ุฎุทโูุด ูโุจุงุดุฏุ ุงูุจุงุฑ ุชุฌุฑุจู ูโุชูุงูุฏ ุจุฒุฑฺฏ ุจุงุดุฏุ ฺฉู ุจู ุงูฺฏูุฑุชู ุงุฌุงุฒู ูโุฏูุฏ ุชุง ุงุฒ ุงุฏฺฏุฑ ูุฌููุนูโุง ุงุฒ ุงูุชูุงูโูุง ูุงููุจุณุชู ุจูุฑูโููุฏ ุดูุฏ.
ฺุงูุด ุงุตู ุงุฏฺฏุฑ ุฏุฑ ูุถุงูุง ุนูู ูพูุณุชูุ ุงฺฉุชุดุงู ุงุณุช. ฺฉ ูุฒุช  ุงูฺฏูุฑุชูโูุง ูุณุชูู ุงุฒ ุฎุทโูุด ูุงููุฏ 
\lr{DDPG}
ุงู ุงุณุช ฺฉู ูโุชูุงู ุจู ูุณุฆูู ฺฉุงูุดุ ูุณุชูู ุงุฒ ุงูฺฏูุฑุชู ุงุฏฺฏุฑ ูพุฑุฏุงุฎุช.
ูโุชูุงู ฺฉ ุฎุทโูุด ุงฺฉุชุดุงู 
$\mu'$
ุฑุง ุจุง ุงุถุงูู ฺฉุฑุฏู ููุฒ (ูููููโฺฏุฑ ุดุฏู ุงุฒ ูุฑุขูุฏ $\EuScript{N}$) ุจู ุฎุทโูุด ุจุงุฒฺฏุฑ ุณุงุฎุช:
\begin{equation}
\mu'(s_t) = \mu(s_t|\theta_t^mu) + \EuScript{N}
\end{equation}
ูโุชูุงู $\EuScript{N}$ 
ุฑุง ูุชูุงุณุจ ุจุง ูุญุท ุงูุชุฎุงุจ ฺฉุฑุฏ.
\ุดุฑูุน{ุงูฺฏูุฑุชู}{ุงูฺฏูุฑุชู DDPG}
\ุฏุณุชูุฑ{ูพุงุฑุงูุชุฑูุง 
	$\theta_\mu$
	 ู 
	 $\theta_Q$
	 ุจู ุชุฑุชุจ ูุฑุจูุท ุจู ุจุงุฒฺฏุฑ 
	 $\mu(s;\theta_\mu)$
	 ู ููุชูุฏ
	 $Q(s,a;\theta_Q)$
	 ุฑุง ููุฏุงุฑุฏู ุงููู ฺฉู.
}
\ุฏุณุชูุฑ{ูพุงุฑุงูุชุฑูุง ุชูุงุจุน ูุฏู $\mu'$ ู $Q'$ ุฑุง ุจุง ูุฒูโูุง 
$\theta_{\mu'} \longleftrightarrow \theta_\mu$
ู
$\theta_{Q'} \longleftarrow \theta_Q$
ููุฏุงุฑุฏู ุงููู ฺฉู
}
\ุฏุณุชูุฑ{ุญุงูุธู ุชฺฉุฑุงุฑูุง $R$ ุฑุง ุจุณุงุฒ}
\โุจูโุงุฒุง{ุจุฑุง ูุฑ ุงูพุฒูุฏ $1...M$}
\ุฏุณุชูุฑ{ฺฉ ุชุงุจุน ููุฒ ุชุตุงุฏู $\mathbb{N}$} ุจุณุงุฒ
\ุฏุณุชูุฑ{ุญุงูุช ุงููู $S_1$ ุฑุง ูุดุงูุฏู ฺฉู}
\โุจูโุงุฒุง{ุจุฑุง $t=1...T$}
\ุฏุณุชูุฑ{ุนูู 
	$a_t = \mu(s_t; \theta_\mu) + \mathbb{N}_t$
	 ุฑุง ุจุฑ ุงุณุงุณ ุฎุทโูุด ูุนู ู ููุฒ ุงฺฉุชุดุงูุ ุงูุชุฎุงุจ ฺฉู ู ุญุงูุช ุจุนุฏ $S_{t+1}$} ู ูพุงุฏุงุด $R_t$ ุฑุง ูุดุงูุฏู ฺฉู.
 \ุฏุณุชูุฑ{ุชุฌุฑุจู 
 	$(s_t, a_t, r_t, s_{t+1})$
 	 ุฑุง ุฏุฑ ุงูุจุงุฑ ุชุฌุฑุจู $R$ ุฐุฎุฑู ฺฉู}
  \ุฏุณุชูุฑ{ฺฉ ููููู ุจู ุงูุฏุงุฒู $N$ ุงุฒ ุชุฌุฑุจูโูุง $(s_i, a_i, r_i, s_{i+1})$ ุงุฒ ุงูุจุงุฑ ุชุฌุฑุจู $R$ ุงูุชุฎุงุจ ฺฉู }
  \ุฏุณุชูุฑ{ูุฒูโูุง ููุชูุฏ $\theta_Q$ ุฑุง ุจุง ุฏุฑูุธุฑ ฺฏุฑูุชู ุชุงุจุน ูุฒูู 
  	$L = \dfrac{1}{N} \sum_i(y_i - Q(S_i, A_i; \theta_Q))^2$
  	 ุจูโุฑูุฒุฑุณุงู ฺฉู}
   \ุฏุณุชูุฑ{ูุฒูโูุง ุจุงุฒฺฏุฑ $\theta_\mi$ ุฑุง ุจุง ุงุณุชูุงุฏู ุงุฒ ฺฏุฑุงุฏุงู ุฎุทโูุด ููููู 
   	$$\nabla_{\theta_\mu} J \approx \dfrac{1}{N} \sum_{i} \nabla_a Q(s,a;\theta_Q) |_{s=s_i, a=\mu(s_i)} \nabla_{\thata_\mu} \mu(s;\theta_\mu) |_{S_i}$$
   	 ุจูโุฑูุฒุฑุณุงู ฺฉู}
   \ุฏุณุชูุฑ{ูุฒูโูุง ุชูุงุจุน ูุฏู ุฑุง ุจู ุดฺฉู 
   	$$\theta_{Q'} = \tau \theta_Q + (1-\tau) \theta_{Q'} \\ \theta_{\mu'} = \tau \theta_\mu + (1-\tau) \theta_{\mu'}$$
   	 ุจูโุฑูุฒุฑุณุงู ฺฉู}
%\ูพุงุงูโุจูโุงุฒุง
%\ูพุงุงูโุจูโุงุฒุง
\ูพุงุงู{ุงูฺฏูุฑุชู}

\subsection{ููุงุณู ุฑูุด ุจูููโุณุงุฒ ุฎุทโูุด ู Q-learning}
ููุทู ููุช ุงุตู ุฑูุดโูุง ุจูููโุณุงุฒ ุฎุทโูุดุ ุงุตูู ุจูุฏู ุขููุงุณุช ุ ุจู ุงู ูุนูุง ฺฉู ุดูุง ูุณุชููุงู ฺุฒ ฺฉู ูโุฎูุงูุฏ ุฑุง ุจูููโุณุงุฒ ูโฺฉูุฏ. ุฏุฑ ูุชุฌู ุงู ุฑูุดโูุง ูุงุจู ุงุชฺฉุง ู ุจุงุซุจุงุช ูุณุชูุฏ. ุฏุฑ ููุงุจูุ ุฑูุดโูุง 
\rl{Q-learning}
ุจุง ุงุฏฺฏุฑ ุชุงุจุน Qุ ููุงุณ ุนููฺฉุฑุฏ ุฑุง ุจู ุทูุฑ ุบุฑ ูุณุชูู ุจููู ูโฺฉูุฏ. ุญุงูุชโูุง ุฒุงุฏ ุจุฑุง ุงู ููุน ุงุฏฺฏุฑ ูุฌูุฏ ุฏุงุฑุฏ ฺฉู ุจู ุดฺฉุณุช ููุชู ูโุดูุฏุ ุจูุงุจุฑุงู ุงู ุฑูุดโูุง  ุซุจุงุช ฺฉูุชุฑ ุฏุงุฑูุฏ 
\cite{suttonbook}.
ุฑูุดโูุง 
\rl{Q-learning}
 ูโุชูุงููุฏ ุงุฒ ุฏุงุฏูโูุง ุจู ุทูุฑ ููุซุฑุชุฑ ูุณุจุช ุจู ุชฺฉูฺฉโูุง ุจูููโุณุงุฒ ุฎุทโูุด ุงุณุชูุงุฏู ฺฉููุฏ.
\paragraph{ุชุนุงูู ุจู ุจูููโุณุงุฒ ุฎุทโูุด ู Q-learning}
 ุจูููโุณุงุฒ ุฎุทโูุด ู  
\lr{Q-learning}
ูุงุณุงุฒฺฏุงุฑ ูุณุชูุฏ (ุจู ูุธุฑ ูโุฑุณุฏ ุชุญุช ุจุฑุฎ ุดุฑุงุทุ ูุนุงุฏู ุขู ุจุงุดุฏ) ู ุทู ูุณุน ุงุฒ ุงูฺฏูุฑุชูโูุง ูุฌูุฏ ุฏุงุฑุฏ ฺฉู ุจู ุฏู ุญุฏ ุงู ุทู ูุฌูุฏ ุฏุงุฑูุฏ. ุงูฺฏูุฑุชูโูุง ฺฉู ุฏุฑ ุงู ุทู ูุฑุงุฑ ุฏุงุฑูุฏ ูุงุฏุฑูุฏ ุงุฒ ููุงุท ููุช  ุทุฑูู ุทู ุงุณุชูุงุฏู ฺฉููุฏ.
  ุจู ุทูุฑ ูุซุงูุ 
 \lr{DDPG}ุงูฺฏูุฑุชูโุงุณุช ฺฉู  ฺฉ ุฎุทโูุด ูุทุน ู ฺฉ ุชุงุจุน Q ุฑุง ุงุฏ ูโฺฏุฑุฏุ
 ุจูโุทูุฑโฺฉู ุงุฒ ูุฑฺฉ  ุจุฑุง ุจูุจูุฏ ุฏฺฏุฑ ุงุณุชูุงุฏ ูโฺฉูุฏ. ุฑูุด
 \lr{SAC}ุ
   ุงุฒ ุฎุทโูุดโูุง ุชุตุงุฏูุ ุชูุธู ุขูุชุฑููพ  \LTRfootnote{entropy regularization}ู ฺูุฏ ุชุฑููุฏ ุฏฺฏุฑ ุจุฑุง  ุงุฏฺฏุฑ ู ฺฉุณุจ ุงูุชุงุฒ ุจุงูุงุชุฑ ุงุฒ 
\lr{DDPG}
    ุฏุฑ ูุญฺฉโูุง ุงุณุชุงูุฏุงุฑุฏ
\LTRfootnote{Standard Benchmark}
    ุงุณุชูุงุฏู ูโฺฉูุฏ.

%\ูุณูุช{ุฑูุดโูุง ูุจุชู ุจุฑ ูุฏู}

%Unlike model-free RL, there arenโt a small number of easy-to-define clusters of methods for model-based RL: there are many orthogonal ways of using models. Weโll give a few examples, but the list is far from exhaustive. In each case, the model may either be given or learned.
%
%Background: Pure Planning. The most basic approach never explicitly represents the policy, and instead, uses pure planning techniques like model-predictive control (MPC) to select actions. In MPC, each time the agent observes the environment, it computes a plan which is optimal with respect to the model, where the plan describes all actions to take over some fixed window of time after the present. (Future rewards beyond the horizon may be considered by the planning algorithm through the use of a learned value function.) The agent then executes the first action of the plan, and immediately discards the rest of it. It computes a new plan each time it prepares to interact with the environment, to avoid using an action from a plan with a shorter-than-desired planning horizon.
%
%The MBMF work explores MPC with learned environment models on some standard benchmark tasks for deep RL.
%Expert Iteration. A straightforward follow-on to pure planning involves using and learning an explicit representation of the policy, \pi_{\theta}(a|s). The agent uses a planning algorithm (like Monte Carlo Tree Search) in the model, generating candidate actions for the plan by sampling from its current policy. The planning algorithm produces an action which is better than what the policy alone would have produced, hence it is an โexpertโ relative to the policy. The policy is afterwards updated to produce an action more like the planning algorithmโs output.
%
%The ExIt algorithm uses this approach to train deep neural networks to play Hex.
%AlphaZero is another example of this approach.
%Data Augmentation for Model-Free Methods. Use a model-free RL algorithm to train a policy or Q-function, but either 1) augment real experiences with fictitious ones in updating the agent, or 2) use only fictitous experience for updating the agent.
%
%See MBVE for an example of augmenting real experiences with fictitious ones.
%See World Models for an example of using purely fictitious experience to train the agent, which they call โtraining in the dream.โ
%Embedding Planning Loops into Policies. Another approach embeds the planning procedure directly into a policy as a subroutineโso that complete plans become side information for the policyโwhile training the output of the policy with any standard model-free algorithm. The key concept is that in this framework, the policy can learn to choose how and when to use the plans. This makes model bias less of a problem, because if the model is bad for planning in some states, the policy can simply learn to ignore it.
%
%See I2A for an example of agents being endowed with this style of imagination.

%\subsection{ุฑูุด ูุฏู ุฌูุงู}
%\ูุณูุช{ุฑูุด ูุฏู ุฌูุงู}
%Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own dream environment generated by its world model, and transfer this policy back into the actual environment.
%ูุฏู ุฌูุงู
%\LTRfootnote{World Models}
% ูโุชูุงูุฏ ุจู ุณุฑุนุช ู ุจู ุฑูุด ุจุฏูู ูุธุงุฑุช ุขููุฒุด ุจุจูุฏ ุชุง ฺฉ ุจุงุฒููุง ุงุฒ ูุญุท ุฑุง ุจุงููุฒุฏ. ุณูพุณ ุจุง ุงุณุชูุงุฏู ุงุฒ ูฺฺฏโูุง ุงุณุชุฎุฑุงุฌ ุดุฏู ุงุฒ ูุฏู ุฌูุงู ุจู ุนููุงู ูุฑูุฏ ุจู ฺฉ ุนุงููุ ูโุชูุงู ฺฉ ุฎุทโูุด ุณุงุฏู ู ูุดุฑุฏู ุฑุง ุขููุฎุช ฺฉู ูโุชูุงูุฏ ูุธูู ููุฑุฏ ูุงุฒ ุฑุง ุญู ฺฉูุฏ. ุญุช ูโุชูุงูู ุนุงูู ุฑุง ฺฉุงููุงู ุฏุฑ ุฏุงุฎู ูุญุท ุฑูุง ุฎูุฏ ฺฉู ุชูุณุท ูุฏู ุฌูุงู ุขู ุงุฌุงุฏ ุดุฏูุ ุขููุฒุด ุฏูู ู ุงู ุฎุทโูุด ุขููุฎุชู ุดุฏู ุฑุง ุจู ูุญุท ูุงูุน ุงูุชูุงู ุฏูู. ุฏุฑ ุจุณุงุฑ ุงุฒ ูุณุงุฆู ุงุฏฺฏุฑ ุชููุช ูุจุชู ุจุฑ ูุฏูุ ุนุงูู ุจู ูุฏู ูุฏุฑุชููุฏ ุงุฒ ุฏูุงูฺฉ ูุญุท ุฏุณุชุฑุณ ุฏุงุฑุฏ.
% \\ุงฺฉุซุฑ ุฑูฺฉุฑุฏูุง ูุจุชู ุจุฑ ูุฏู ููุฌูุฏ ุฏุฑ ุงุฏฺฏุฑ ุชููุชุ ูุฏู ุงุฒ ูุญุท ุฑุง ุงุฏ ูโฺฏุฑูุฏุ ุงูุง ููฺูุงู ุฏุฑ ูุญุท ูุงูุน ุขููุฒุด ูโุจููุฏ. ุฏุฑ ุงู ุฑูุดุ ูุง ููฺูู ูโุชูุงูู ฺฉ ูุญุท  ูุตููุน ุฑุง ฺฉุงููุงู ุฌุงฺฏุฒู ูุญุท ูุงูุน ฺฉูู ู ุฎุทโูุด ุนุงูู ุฎูุฏ ุฑุง ููุท ุฏุฑ ุฏุงุฎู ูุญุท ูุตููุน ุขููุฒุด ุฏูู ู ุฏุฑููุงุช ุฎุทโูุด ุขููุฎุชู ุดุฏู ุฑุง ุจู ูุญุท ูุงูุน ุงูุชูุงู ุฏูู.

%We present a simple model inspired by our own cognitive system. In this model, our agent has a visual sensory component that compresses what it sees into a small representative code. It also has a memory component that makes predictions about future codes based on historical information. Finally, our agent has a decision-making component that decides what actions to take based only on the representations created by its vision and memory components.