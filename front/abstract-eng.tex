
% -------------------------------------------------------
%  English Abstract
% -------------------------------------------------------


\pagestyle{empty}

\begin{latin}

\begin{center}
\textbf{Abstract}
\end{center}
\baselineskip=.8\baselineskip

In this Thesis, we reviewed some methods based on discrete Reinforcement Learning and their essential algorithms.
Our goal was to give the existing methods an integrated and formal structure, Without compromising their mathematical accuracy or comprehensibility.
We have fixed inconsistencies in notation and definitions between different methods.
We also have explained the definitions and concepts present in all methods separately and the concepts used in only one method in its own section.
We discussed Dynamic programming methods, including policy iteration and value iteration, temporal difference methods, policy-based methods such as Policy gradient, Advantage Actor-Critic, TRPO, and PPO.
Among value-based methods, we discussed
Q-learning And C51
We also reviewed some intermediate methods which use the ideas of both approaches, such as DDPG And SAC.
We used examples when necessary to clarify the matter.
Finally, to summarize, we have given some comparisons of these methods. 


\bigskip\noindent\textbf{Keywords}:
Reinforcement Learning, Dynamic Programming, Machine Learning, Deep Learning

\end{latin}

\newpage
