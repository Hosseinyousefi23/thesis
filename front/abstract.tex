
% -------------------------------------------------------
%  Abstract
% -------------------------------------------------------


\pagestyle{empty}

\شروع{وسط‌چین}
\مهم{چکیده}
\پایان{وسط‌چین}
\بدون‌تورفتگی
نظریه یادگیری تقویتی 
\lr{(RL)}،
به تدریج به یکی از فعال\nf ترین حوزه\nf های تحقیقاتی در یادگیری ماشین و هوش مصنوعی تبدیل شده، که ریشه در دیدگاه\nf های روانشناختی و علوم اعصاب درباره رفتار حیوانات و انسان دارد. یادگیری تقویتی تلاش می\nf کند به این سوال پاسخ دهد: چه کار کنیم که بیش\nf ترین پاداش یا کم\nf ترین هزینه نصیبمان شود؟ این که چگونه عوامل هوشمند می\nf توانند کنترل خود را روی محیط، بهینه کنند نیز در حوزه یادگیری تقویتی قرار می\nf گیرد. عوامل هوشمند با کاری دشوار روبرو می شوند: آنها باید مدل\nf های کارآمدی از محیط را با استفاده از ورودی\nf های حسی بدست آورند و از این مدل\nf ها برای تعمیم تجربه گذشته به موقعیت\nf های جدید استفاده کنند. به نظر می\nf رسد انسان و سایر حیوانات، این مشکل را از طریق ترکیب هماهنگ یادگیری تقویتی و سیستم\nf های حسی سلسله مراتبی حل می\nf کنند. در این پایان نامه، به بررسی روش های مبتنی بر یادگیری تقویتی در حالت گسسته می‌پردازیم و الگوریتم\nf های مهم آن را مرور خواهیم\nf کرد. نهایتا، این الگوریتم\nf ها را روی چند مثال مختلف مقایسه می\nf کنیم.

\پرش‌بلند
\بدون‌تورفتگی \مهم{کلیدواژه‌ها}: 
یادگیری تقویتی
\صفحه‌جدید
