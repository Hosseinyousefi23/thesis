
% -------------------------------------------------------
%  Abstract
% -------------------------------------------------------


\pagestyle{empty}

\شروع{وسط‌چین}
\مهم{چکیده}
\پایان{وسط‌چین}
\بدون‌تورفتگی
 در این پایان نامه، به معرفی برخی از روش های مبتنی بر یادگیری تقویتی در حالت گسسته می\nf پردازیم و الگوریتم\nf های مهم آن را مرور خواهیم\nf کرد. 
هدف ما این بود که به روش\nf های موجود ساختاری یکپارچه و رسمی ببخشیم،
 بدون اینکه از دقت ریاضی یا قابل فهم بودن آن\nf ها کاسته شود.
 مشکلات مربوط به عدم یکپارچگی در نشانه گذاری را اصلاح کردیم.
 تعاریف و مفاهیمی که در همه روش\nf ها حضور دارند را جداگانه توضیح دادیم و مفاهیمی که تنها در یک روش، مورد استفاده قرار می\nf گیرند را در قسمت مربوط به خودش توضیح دادیم.
همچنین در مواقع لزوم، برای روشن شدن مطلب، از مثال استفاده کردیم.
روش\nf های برنامه ریزی پویا، شامل تکرار خط\nf مشی و تکرار ارزش، روش\nf های تفاوت زمانی، روش\nf های مبتنی بر خط\nf مشی مانند گرادیان خط\nf مشی کلاسیک، روش\nf های 
\lr{Actor-Critic},
\lr{TRPO}
و
\lr{PPO}
و در روش\nf های مبتنی بر ارزش، روش
\lr{Q-learning}
و
\lr{c51}
را معرفی کردیم. همچنین روش\nf های میانی 
\lr{DDPG}
و
\lr{SAC}
که از ایده\nf های هر دو رویکرد، استفاده می\nf کنند را بررسی کردیم.
در انتها برای جمع بندی، برخی از مقایسه\nf هایی که از این روش\nf ها صورت گرفته را آورده ایم

\پرش‌بلند
\بدون‌تورفتگی \مهم{کلیدواژه‌ها}: 
یادگیری تقویتی
\صفحه‌جدید
